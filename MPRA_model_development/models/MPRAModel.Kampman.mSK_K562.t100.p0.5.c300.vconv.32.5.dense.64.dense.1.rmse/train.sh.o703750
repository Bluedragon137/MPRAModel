2022-09-27 20:29:43.893322: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-27 20:29:49.310818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9653 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5
2022-09-27 20:29:49.315352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9653 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5
2022-09-27 20:29:49.318211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9653 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:60:00.0, compute capability: 7.5
2022-09-27 20:29:49.320905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 9653 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:61:00.0, compute capability: 7.5
2022-09-27 20:29:49.323639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 9653 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b1:00.0, compute capability: 7.5
2022-09-27 20:29:49.326349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 9653 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b2:00.0, compute capability: 7.5
2022-09-27 20:29:49.328871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 9653 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:da:00.0, compute capability: 7.5
2022-09-27 20:29:49.331738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 9653 MB memory:  -> device: 7, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:db:00.0, compute capability: 7.5
WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.
here
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 sequence (InputLayer)          [(None, 2114, 4)]    0           []                               
                                                                                                  
 wo_bias_bpnet_1st_conv (Conv1D  (None, 2094, 512)   43520       ['sequence[0][0]']               
 )                                                                                                
                                                                                                  
 wo_bias_bpnet_1conv (Conv1D)   (None, 2090, 512)    786944      ['wo_bias_bpnet_1st_conv[0][0]'] 
                                                                                                  
 wo_bias_bpnet_1crop (Cropping1  (None, 2090, 512)   0           ['wo_bias_bpnet_1st_conv[0][0]'] 
 D)                                                                                               
                                                                                                  
 add (Add)                      (None, 2090, 512)    0           ['wo_bias_bpnet_1conv[0][0]',    
                                                                  'wo_bias_bpnet_1crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_2conv (Conv1D)   (None, 2082, 512)    786944      ['add[0][0]']                    
                                                                                                  
 wo_bias_bpnet_2crop (Cropping1  (None, 2082, 512)   0           ['add[0][0]']                    
 D)                                                                                               
                                                                                                  
 add_1 (Add)                    (None, 2082, 512)    0           ['wo_bias_bpnet_2conv[0][0]',    
                                                                  'wo_bias_bpnet_2crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_3conv (Conv1D)   (None, 2066, 512)    786944      ['add_1[0][0]']                  
                                                                                                  
 wo_bias_bpnet_3crop (Cropping1  (None, 2066, 512)   0           ['add_1[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_2 (Add)                    (None, 2066, 512)    0           ['wo_bias_bpnet_3conv[0][0]',    
                                                                  'wo_bias_bpnet_3crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_4conv (Conv1D)   (None, 2034, 512)    786944      ['add_2[0][0]']                  
                                                                                                  
 wo_bias_bpnet_4crop (Cropping1  (None, 2034, 512)   0           ['add_2[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_3 (Add)                    (None, 2034, 512)    0           ['wo_bias_bpnet_4conv[0][0]',    
                                                                  'wo_bias_bpnet_4crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_5conv (Conv1D)   (None, 1970, 512)    786944      ['add_3[0][0]']                  
                                                                                                  
 wo_bias_bpnet_5crop (Cropping1  (None, 1970, 512)   0           ['add_3[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_4 (Add)                    (None, 1970, 512)    0           ['wo_bias_bpnet_5conv[0][0]',    
                                                                  'wo_bias_bpnet_5crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_6conv (Conv1D)   (None, 1842, 512)    786944      ['add_4[0][0]']                  
                                                                                                  
 wo_bias_bpnet_6crop (Cropping1  (None, 1842, 512)   0           ['add_4[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_5 (Add)                    (None, 1842, 512)    0           ['wo_bias_bpnet_6conv[0][0]',    
                                                                  'wo_bias_bpnet_6crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_7conv (Conv1D)   (None, 1586, 512)    786944      ['add_5[0][0]']                  
                                                                                                  
 wo_bias_bpnet_7crop (Cropping1  (None, 1586, 512)   0           ['add_5[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_6 (Add)                    (None, 1586, 512)    0           ['wo_bias_bpnet_7conv[0][0]',    
                                                                  'wo_bias_bpnet_7crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_8conv (Conv1D)   (None, 1074, 512)    786944      ['add_6[0][0]']                  
                                                                                                  
 wo_bias_bpnet_8crop (Cropping1  (None, 1074, 512)   0           ['add_6[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_7 (Add)                    (None, 1074, 512)    0           ['wo_bias_bpnet_8conv[0][0]',    
                                                                  'wo_bias_bpnet_8crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_prof_out_precrop  (None, 1000, 1)     38401       ['add_7[0][0]']                  
  (Conv1D)                                                                                        
                                                                                                  
 wo_bias_bpnet_logitt_before_fl  (None, 1000, 1)     0           ['wo_bias_bpnet_prof_out_precrop[
 atten (Cropping1D)                                              0][0]']                          
                                                                                                  
 gap (GlobalAveragePooling1D)   (None, 512)          0           ['add_7[0][0]']                  
                                                                                                  
 wo_bias_bpnet_logits_profile_p  (None, 1000)        0           ['wo_bias_bpnet_logitt_before_fla
 redictions (Flatten)                                            tten[0][0]']                     
                                                                                                  
 wo_bias_bpnet_logcount_predict  (None, 1)           513         ['gap[0][0]']                    
 ions (Dense)                                                                                     
                                                                                                  
==================================================================================================
Total params: 6,377,986
Trainable params: 6,377,986
Non-trainable params: 0
__________________________________________________________________________________________________
None
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 model_1 (Functional)           [(None, 1000),       6377986     ['input_1[0][0]',                
                                 (None, 1)]                       'input_2[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 1000)         0           ['model_1[0][0]',                
                                                                  'model_1[0][1]']                
                                                                                                  
 lambda_1 (Lambda)              (None, 1000)         0           ['model_1[1][0]',                
                                                                  'model_1[1][1]']                
                                                                                                  
 lambda_2 (Lambda)              (None, 1000)         0           ['lambda[0][0]',                 
                                                                  'lambda_1[0][0]']               
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 1000, 1)      0           ['lambda_2[0][0]']               
                                                                                                  
 conv1d (Conv1D)                (None, 996, 32)      192         ['tf.expand_dims[0][0]']         
                                                                                                  
 flatten (Flatten)              (None, 31872)        0           ['conv1d[0][0]']                 
                                                                                                  
 dense (Dense)                  (None, 64)           2039872     ['flatten[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 1)            65          ['dense[0][0]']                  
                                                                                                  
==================================================================================================
Total params: 8,418,115
Trainable params: 8,418,115
Non-trainable params: 0
__________________________________________________________________________________________________
None
(135, 2114, 4) (135, 2114, 4) (135,)
LR: 0.0001
Epoch 1/40
2022-09-27 20:29:54.518735: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201
2022-09-27 20:29:56.639143: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
1/7 [===>..........................] - ETA: 1:10 - loss: 0.1424 - root_mean_squared_error: 0.14242/7 [=======>......................] - ETA: 1s - loss: 0.1337 - root_mean_squared_error: 0.1340  3/7 [===========>..................] - ETA: 1s - loss: 0.1293 - root_mean_squared_error: 0.12964/7 [================>.............] - ETA: 0s - loss: 0.1317 - root_mean_squared_error: 0.13205/7 [====================>.........] - ETA: 0s - loss: 0.1250 - root_mean_squared_error: 0.12606/7 [========================>.....] - ETA: 0s - loss: 0.1271 - root_mean_squared_error: 0.12807/7 [==============================] - ETA: 0s - loss: 0.1299 - root_mean_squared_error: 0.1309
Epoch 1: val_loss improved from inf to 0.11062, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.32.5.dense.64.dense.1.rmse
2022-09-27 20:30:08.943465: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
7/7 [==============================] - 21s 2s/step - loss: 0.1299 - root_mean_squared_error: 0.1309 - val_loss: 0.1106 - val_root_mean_squared_error: 0.1109
Epoch 2/40
1/7 [===>..........................] - ETA: 2s - loss: 0.1175 - root_mean_squared_error: 0.11752/7 [=======>......................] - ETA: 1s - loss: 0.1105 - root_mean_squared_error: 0.11083/7 [===========>..................] - ETA: 1s - loss: 0.1042 - root_mean_squared_error: 0.10474/7 [================>.............] - ETA: 0s - loss: 0.1008 - root_mean_squared_error: 0.10145/7 [====================>.........] - ETA: 0s - loss: 0.1054 - root_mean_squared_error: 0.10636/7 [========================>.....] - ETA: 0s - loss: 0.1025 - root_mean_squared_error: 0.10357/7 [==============================] - ETA: 0s - loss: 0.1021 - root_mean_squared_error: 0.1029
Epoch 2: val_loss did not improve from 0.11062
7/7 [==============================] - 2s 345ms/step - loss: 0.1021 - root_mean_squared_error: 0.1029 - val_loss: 0.1200 - val_root_mean_squared_error: 0.1203
Epoch 3/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0836 - root_mean_squared_error: 0.08362/7 [=======>......................] - ETA: 1s - loss: 0.0794 - root_mean_squared_error: 0.07953/7 [===========>..................] - ETA: 1s - loss: 0.0796 - root_mean_squared_error: 0.07964/7 [================>.............] - ETA: 0s - loss: 0.0742 - root_mean_squared_error: 0.07485/7 [====================>.........] - ETA: 0s - loss: 0.0788 - root_mean_squared_error: 0.07986/7 [========================>.....] - ETA: 0s - loss: 0.0756 - root_mean_squared_error: 0.07687/7 [==============================] - ETA: 0s - loss: 0.0731 - root_mean_squared_error: 0.0745
Epoch 3: val_loss improved from 0.11062 to 0.10890, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.32.5.dense.64.dense.1.rmse
7/7 [==============================] - 7s 1s/step - loss: 0.0731 - root_mean_squared_error: 0.0745 - val_loss: 0.1089 - val_root_mean_squared_error: 0.1092
Epoch 4/40
1/7 [===>..........................] - ETA: 2s - loss: 0.0661 - root_mean_squared_error: 0.06612/7 [=======>......................] - ETA: 1s - loss: 0.0609 - root_mean_squared_error: 0.06113/7 [===========>..................] - ETA: 1s - loss: 0.0584 - root_mean_squared_error: 0.05864/7 [================>.............] - ETA: 0s - loss: 0.0534 - root_mean_squared_error: 0.05435/7 [====================>.........] - ETA: 0s - loss: 0.0526 - root_mean_squared_error: 0.05336/7 [========================>.....] - ETA: 0s - loss: 0.0514 - root_mean_squared_error: 0.05217/7 [==============================] - ETA: 0s - loss: 0.0511 - root_mean_squared_error: 0.0517
Epoch 4: val_loss did not improve from 0.10890
7/7 [==============================] - 2s 346ms/step - loss: 0.0511 - root_mean_squared_error: 0.0517 - val_loss: 0.1149 - val_root_mean_squared_error: 0.1152
Epoch 5/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0653 - root_mean_squared_error: 0.06532/7 [=======>......................] - ETA: 1s - loss: 0.0537 - root_mean_squared_error: 0.05503/7 [===========>..................] - ETA: 1s - loss: 0.0470 - root_mean_squared_error: 0.04894/7 [================>.............] - ETA: 0s - loss: 0.0398 - root_mean_squared_error: 0.04335/7 [====================>.........] - ETA: 0s - loss: 0.0396 - root_mean_squared_error: 0.04246/7 [========================>.....] - ETA: 0s - loss: 0.0421 - root_mean_squared_error: 0.04477/7 [==============================] - ETA: 0s - loss: 0.0403 - root_mean_squared_error: 0.0430
Epoch 5: val_loss did not improve from 0.10890
7/7 [==============================] - 2s 346ms/step - loss: 0.0403 - root_mean_squared_error: 0.0430 - val_loss: 0.1142 - val_root_mean_squared_error: 0.1156
Epoch 6/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0240 - root_mean_squared_error: 0.02402/7 [=======>......................] - ETA: 1s - loss: 0.0292 - root_mean_squared_error: 0.02973/7 [===========>..................] - ETA: 1s - loss: 0.0286 - root_mean_squared_error: 0.02894/7 [================>.............] - ETA: 0s - loss: 0.0293 - root_mean_squared_error: 0.02965/7 [====================>.........] - ETA: 0s - loss: 0.0301 - root_mean_squared_error: 0.03046/7 [========================>.....] - ETA: 0s - loss: 0.0308 - root_mean_squared_error: 0.03117/7 [==============================] - ETA: 0s - loss: 0.0331 - root_mean_squared_error: 0.0339
Epoch 6: val_loss did not improve from 0.10890
7/7 [==============================] - 2s 348ms/step - loss: 0.0331 - root_mean_squared_error: 0.0339 - val_loss: 0.1351 - val_root_mean_squared_error: 0.1369
Epoch 7/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0304 - root_mean_squared_error: 0.03042/7 [=======>......................] - ETA: 1s - loss: 0.0366 - root_mean_squared_error: 0.03713/7 [===========>..................] - ETA: 1s - loss: 0.0304 - root_mean_squared_error: 0.03204/7 [================>.............] - ETA: 0s - loss: 0.0317 - root_mean_squared_error: 0.03305/7 [====================>.........] - ETA: 0s - loss: 0.0356 - root_mean_squared_error: 0.03746/7 [========================>.....] - ETA: 0s - loss: 0.0401 - root_mean_squared_error: 0.04267/7 [==============================] - ETA: 0s - loss: 0.0400 - root_mean_squared_error: 0.0423
Epoch 7: val_loss did not improve from 0.10890
7/7 [==============================] - 2s 350ms/step - loss: 0.0400 - root_mean_squared_error: 0.0423 - val_loss: 0.1163 - val_root_mean_squared_error: 0.1174
Epoch 8/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0355 - root_mean_squared_error: 0.03552/7 [=======>......................] - ETA: 1s - loss: 0.0284 - root_mean_squared_error: 0.02933/7 [===========>..................] - ETA: 1s - loss: 0.0299 - root_mean_squared_error: 0.03054/7 [================>.............] - ETA: 0s - loss: 0.0300 - root_mean_squared_error: 0.03055/7 [====================>.........] - ETA: 0s - loss: 0.0299 - root_mean_squared_error: 0.03036/7 [========================>.....] - ETA: 0s - loss: 0.0300 - root_mean_squared_error: 0.03037/7 [==============================] - ETA: 0s - loss: 0.0304 - root_mean_squared_error: 0.0307
Epoch 8: val_loss did not improve from 0.10890
Restoring model weights from the end of the best epoch: 3.
7/7 [==============================] - 2s 355ms/step - loss: 0.0304 - root_mean_squared_error: 0.0307 - val_loss: 0.1179 - val_root_mean_squared_error: 0.1186
Epoch 8: early stopping
TNN loaded from file
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 model_1 (Functional)           [(None, 1000),       6377986     ['input_1[0][0]',                
                                 (None, 1)]                       'input_2[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 1000)         0           ['model_1[0][0]',                
                                                                  'model_1[0][1]']                
                                                                                                  
 lambda_1 (Lambda)              (None, 1000)         0           ['model_1[1][0]',                
                                                                  'model_1[1][1]']                
                                                                                                  
 lambda_2 (Lambda)              (None, 1000)         0           ['lambda[0][0]',                 
                                                                  'lambda_1[0][0]']               
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 1000, 1)      0           ['lambda_2[0][0]']               
                                                                                                  
 conv1d (Conv1D)                (None, 996, 32)      192         ['tf.expand_dims[0][0]']         
                                                                                                  
 flatten (Flatten)              (None, 31872)        0           ['conv1d[0][0]']                 
                                                                                                  
 dense (Dense)                  (None, 64)           2039872     ['flatten[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 1)            65          ['dense[0][0]']                  
                                                                                                  
==================================================================================================
Total params: 8,418,115
Trainable params: 8,418,115
Non-trainable params: 0
__________________________________________________________________________________________________
None
 1/10 [==>...........................] - ETA: 4s 2/10 [=====>........................] - ETA: 0s 3/10 [========>.....................] - ETA: 0s 4/10 [===========>..................] - ETA: 0s 5/10 [==============>...............] - ETA: 0s 6/10 [=================>............] - ETA: 0s 7/10 [====================>.........] - ETA: 0s 8/10 [=======================>......] - ETA: 0s 9/10 [==========================>...] - ETA: 0s10/10 [==============================] - ETA: 0s10/10 [==============================] - 2s 202ms/step
[-0.059547387, -0.09696173, 0.066199355, 0.04539136, -0.29832044, -0.057023056, -0.06542068, 0.0062542497, -0.08765074, 0.007601139, -0.045755386, -0.086828984, -0.020008521, -0.18617463, -0.04928681, -0.056776464, -0.09590112, -0.01665134, 0.10136739, 0.0017506998, 0.033732295, -0.041965343, 0.066294916, 0.030671548, 0.04345616, 0.017938158, 0.061015923, 0.12610921, -0.10750132, -0.007905215, -0.050595827, -0.032599557, 0.0016871643, 0.08816951, 0.023444327, 0.08874412, 0.05139764, -0.013927089, -0.052815124, -0.061654035, -0.038249146, 0.02047725, 0.02658137, -0.07639574, 0.04507837, 0.062491868, 0.014580241, -0.12325286, -0.19212183, -0.044111237, 0.08065687, 0.06265152, 0.07870942, -0.18443285, 0.017039817, 0.005896362, 0.07732185, 0.09406634, 0.08515055, -0.062294193, -0.09713937, -0.05467604, -0.015839256, 0.053377032, 0.0267127, 0.035986874, -0.11283715, 0.04306102, -0.07155999, 0.0760991, 0.07988444, 0.13228491, -0.48124, 0.024071164, -0.07188709, -0.12861003, -0.020244662, 0.034186065, 0.19261602, 0.050438996, -0.091872536, 0.016600514, 0.051853314, 0.09401604, 0.021153279, -0.011974719, -0.07831705, 0.09570692, -0.06365939, 0.08774494, -0.056764174, -0.12459932, 0.008836177, -0.019082101, -0.12670194, 0.05321246, -0.12621872, 0.14977664, -0.07349343, -0.018721735, 0.032249033, -0.12815188, -0.016119637, -0.027773766, 0.03339548, -0.15608886, -0.07951508, -0.050813537, 0.04323287, -0.17017992, -0.0024349992, -0.09349053, 0.10105663, 0.04040068, -0.11479197, -0.13967574, -0.13093457, 0.034069248, -0.104494475, 0.06654612, -0.12981279, -0.051285204, -0.00013920401, -0.12284703, 0.106785566, 0.14447697, 0.1790955, -0.19006905, 0.07943074, -0.0134566575, 0.1513542, 0.20107962, -0.11860887, -0.07506916, -0.13067138, 0.055190776, 0.16618492, -0.03553895, -0.07487374, -0.07796534, 0.19314891, -0.043520093, -0.12813364, -0.25725746, 0.1511174, -0.19578779, -0.26231217, 0.16725384, -0.3528387, -0.32807845, -0.5871849]
[-0.0905034  -0.09947216  0.07853377  0.07739935 -0.26832333 -0.06778263
 -0.08546479  0.08648197  0.07961277  0.07720217 -0.08014117 -0.08105874
 -0.09328441 -0.09695353 -0.11880182 -0.06326722 -0.08434247 -0.09411035
  0.0921365   0.09063613  0.12313518 -0.07950069  0.09031201  0.0710011
 -0.10043573  0.11124648  0.10079366  0.09531208 -0.06277929 -0.11083511
 -0.10710893 -0.11494793  0.13846627  0.11033365  0.09340035  0.09148435
  0.0829305  -0.06689062 -0.07912685 -0.08899292 -0.09257795  0.0991051
  0.08540135 -0.10334674  0.11694617  0.10851879  0.08058769 -0.12419123
 -0.12557973 -0.06900014  0.15094079  0.14292263  0.11062875 -0.16626157
  0.12909251  0.07481506  0.10535965  0.09083616  0.10223201 -0.07872573
 -0.08115115 -0.10202431  0.1065836   0.10569526  0.09134408 -0.10430546
 -0.11229523  0.08098407 -0.07248487  0.10833224  0.11191964  0.09127144
 -0.34156207  0.16014625 -0.10213176 -0.1030441   0.18302456  0.08710979
  0.16541972  0.15007845 -0.11375303 -0.13332473  0.15195966  0.10983172
 -0.12349412 -0.11492698 -0.15814887  0.08052575 -0.11003885  0.08794768
 -0.10758457 -0.14492674  0.11402104 -0.10341273 -0.11568559  0.11976604
 -0.09906955  0.11174096 -0.11254208 -0.1282223   0.0830264  -0.1545139
 -0.1043491  -0.14034679  0.11594063 -0.13771265 -0.16025063 -0.14683859
  0.1183183  -0.1315937  -0.13619249 -0.12484662  0.15976923  0.10062947
 -0.11664557 -0.1552405  -0.17203074  0.1055946  -0.10456964  0.14444356
 -0.11645929 -0.17384205  0.10422415 -0.12774052  0.12609592  0.12372607
  0.23101375 -0.2028399  -0.22582155  0.17918628  0.12624905  0.20775655
 -0.1733779  -0.18529817 -0.1419532   0.16041179  0.15815749 -0.18451102
 -0.19436191 -0.19201529  0.18251119 -0.17792116 -0.17916801 -0.23552507
  0.18936244 -0.22218015 -0.3508249   0.29389578 -0.33032155 -0.29608878
 -0.52658078]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 151 entries, 0 to 150
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   TNN     151 non-null    float32
 1   Y       151 non-null    float64
dtypes: float32(1), float64(1)
memory usage: 1.9 KB
None
         TNN         Y
0  -0.059547 -0.090503
1  -0.096962 -0.099472
2   0.066199  0.078534
3   0.045391  0.077399
4  -0.298320 -0.268323
5  -0.057023 -0.067783
6  -0.065421 -0.085465
7   0.006254  0.086482
8  -0.087651  0.079613
9   0.007601  0.077202
10 -0.045755 -0.080141
11 -0.086829 -0.081059
12 -0.020009 -0.093284
13 -0.186175 -0.096954
14 -0.049287 -0.118802
15 -0.056776 -0.063267
16 -0.095901 -0.084342
17 -0.016651 -0.094110
18  0.101367  0.092136
19  0.001751  0.090636
1/9 [==>...........................] - ETA: 0s2/9 [=====>........................] - ETA: 0s3/9 [=========>....................] - ETA: 0s4/9 [============>.................] - ETA: 0s5/9 [===============>..............] - ETA: 0s6/9 [===================>..........] - ETA: 0s7/9 [======================>.......] - ETA: 0s8/9 [=========================>....] - ETA: 0s9/9 [==============================] - ETA: 0s9/9 [==============================] - 1s 96ms/step
[-0.09590112, 0.033732295, -0.044111237, 0.04306102, 0.19314891, -0.07951508, -0.07831705, -0.052815124, -0.15608886, -0.061654035, -0.07349343, -0.25725746, -0.050813537, 0.06265152, -0.12670194, -0.09349053, 0.07870942, -0.12621872, 0.0267127, 0.04539136, 0.08515055, 0.032249033, -0.12981279, -0.020008521, 0.08874412, -0.091872536, 0.066294916, -0.19212183, 0.08816951, 0.1790955, -0.17017992, 0.007601139, 0.10136739, -0.48124, 0.16618492, -0.01665134, -0.086828984, 0.1511174, 0.04040068, -0.051285204, -0.29832044, 0.14977664, -0.059547387, -0.09713937, 0.034186065, 0.09570692, 0.07732185, -0.043520093, -0.038249146, -0.10750132, 0.017938158, 0.0017506998, -0.056776464, -0.041965343, 0.106785566, 0.14447697, -0.07639574, 0.014580241, 0.08065687, -0.057023056, -0.13967574, -0.12459932, 0.034069248, -0.5871849, -0.07188709, 0.20107962, 0.04507837, 0.09406634, 0.055190776, 0.02658137, -0.19006905, -0.11860887, 0.0760991, -0.0024349992, -0.056764174, 0.09401604, -0.18443285, 0.04323287, 0.12610921, 0.061015923, 0.066199355, 0.062491868, 0.023444327, 0.06654612, 0.13228491, -0.07155999, 0.02047725, 0.053377032, -0.11283715, -0.12325286, 0.19261602, -0.05467604, -0.32807845, -0.19578779, -0.050595827, -0.04928681, -0.3528387, -0.018721735, -0.12813364, 0.08774494, 0.008836177, -0.06365939, 0.10105663, 0.1513542, -0.11479197, -0.09696173, -0.062294193, -0.13067138, -0.12861003, 0.0016871643, -0.13093457, -0.007905215, 0.017039817, 0.07943074, 0.030671548, -0.027773766, 0.021153279, -0.18617463, 0.07988444, -0.06542068, 0.05139764, 0.16725384, 0.050438996, -0.013927089, -0.045755386, -0.015839256, -0.016119637, 0.016600514, 0.035986874, -0.104494475, 0.005896362, 0.03339548, -0.019082101, -0.07506916, -0.07796534]
[-0.08434247  0.12313518 -0.06900014  0.08098407  0.18251119 -0.16025063
 -0.15814887 -0.07912685 -0.13771265 -0.08899292 -0.11254208 -0.23552507
 -0.14683859  0.14292263 -0.11568559 -0.12484662  0.11062875 -0.09906955
  0.09134408  0.07739935  0.10223201  0.0830264  -0.11645929 -0.09328441
  0.09148435 -0.11375303  0.09031201 -0.12557973  0.11033365  0.23101375
 -0.1315937   0.07720217  0.0921365  -0.34156207  0.15815749 -0.09411035
 -0.08105874  0.18936244  0.10062947 -0.17384205 -0.26832333  0.11174096
 -0.0905034  -0.08115115  0.08710979  0.08052575  0.10535965 -0.17792116
 -0.09257795 -0.06277929  0.11124648  0.09063613 -0.06326722 -0.07950069
  0.12609592  0.12372607 -0.10334674  0.08058769  0.15094079 -0.06778263
 -0.1552405  -0.14492674  0.1055946  -0.52658078 -0.10213176  0.20775655
  0.11694617  0.09083616  0.16041179  0.08540135 -0.2028399  -0.1733779
  0.10833224 -0.13619249 -0.10758457  0.10983172 -0.16626157  0.1183183
  0.09531208  0.10079366  0.07853377  0.10851879  0.09340035  0.14444356
  0.09127144 -0.07248487  0.0991051   0.10569526 -0.11229523 -0.12419123
  0.16541972 -0.10202431 -0.29608878 -0.22218015 -0.10710893 -0.11880182
 -0.33032155 -0.1282223  -0.17916801  0.08794768  0.11402104 -0.11003885
  0.15976923  0.12624905 -0.11664557 -0.09947216 -0.07872573 -0.1419532
 -0.1030441   0.13846627 -0.17203074 -0.11083511  0.12909251 -0.22582155
  0.0710011  -0.14034679 -0.12349412 -0.09695353  0.11191964 -0.08546479
  0.0829305   0.29389578  0.15007845 -0.06689062 -0.08014117  0.1065836
 -0.1043491  -0.13332473 -0.10430546 -0.10456964  0.07481506  0.11594063
 -0.10341273 -0.18529817 -0.19201529]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 135 entries, 0 to 134
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   TNN     135 non-null    float32
 1   Y       135 non-null    float64
dtypes: float32(1), float64(1)
memory usage: 1.7 KB
None
         TNN         Y
0  -0.095901 -0.084342
1   0.033732  0.123135
2  -0.044111 -0.069000
3   0.043061  0.080984
4   0.193149  0.182511
5  -0.079515 -0.160251
6  -0.078317 -0.158149
7  -0.052815 -0.079127
8  -0.156089 -0.137713
9  -0.061654 -0.088993
10 -0.073493 -0.112542
11 -0.257257 -0.235525
12 -0.050814 -0.146839
13  0.062652  0.142923
14 -0.126702 -0.115686
15 -0.093491 -0.124847
16  0.078709  0.110629
17 -0.126219 -0.099070
18  0.026713  0.091344
19  0.045391  0.077399
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 389ms/step
[0.0062542497, -0.020244662, -0.03553895, -0.26231217, -0.0134566575, -0.032599557, 0.05321246, 0.051853314, 0.024071164, 0.04345616, -0.011974719, -0.07487374, -0.08765074, -0.12284703, -0.00013920401, -0.12815188]
[ 0.08648197  0.18302456 -0.18451102 -0.3508249   0.17918628 -0.11494793
  0.11976604  0.15195966  0.16014625 -0.10043573 -0.11492698 -0.19436191
  0.07961277 -0.12774052  0.10422415 -0.1545139 ]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 16 entries, 0 to 15
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   TNN     16 non-null     float32
 1   Y       16 non-null     float64
dtypes: float32(1), float64(1)
memory usage: 320.0 bytes
None
         TNN         Y
0   0.006254  0.086482
1  -0.020245  0.183025
2  -0.035539 -0.184511
3  -0.262312 -0.350825
4  -0.013457  0.179186
5  -0.032600 -0.114948
6   0.053212  0.119766
7   0.051853  0.151960
8   0.024071  0.160146
9   0.043456 -0.100436
10 -0.011975 -0.114927
11 -0.074874 -0.194362
12 -0.087651  0.079613
13 -0.122847 -0.127741
14 -0.000139  0.104224
15 -0.128152 -0.154514
spearman TNN-all: 0.8019588706866503
pearson TNN-all: 0.8473094683671488
spearman TNN-train: 0.8277143693298217
pearson TNN-train: 0.8732113084483516
spearman TNN-test: 0.6735294117647058
pearson TNN-test: 0.6993053230409657
