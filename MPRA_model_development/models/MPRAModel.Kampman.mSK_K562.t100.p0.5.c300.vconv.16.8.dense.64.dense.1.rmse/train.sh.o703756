2022-09-27 20:34:43.184518: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-27 20:34:46.398003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22846 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:1a:00.0, compute capability: 7.5
2022-09-27 20:34:46.401978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22846 MB memory:  -> device: 1, name: NVIDIA TITAN RTX, pci bus id: 0000:60:00.0, compute capability: 7.5
2022-09-27 20:34:46.403935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22846 MB memory:  -> device: 2, name: NVIDIA TITAN RTX, pci bus id: 0000:b1:00.0, compute capability: 7.5
2022-09-27 20:34:46.405709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22846 MB memory:  -> device: 3, name: NVIDIA TITAN RTX, pci bus id: 0000:da:00.0, compute capability: 7.5
WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.
here
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 sequence (InputLayer)          [(None, 2114, 4)]    0           []                               
                                                                                                  
 wo_bias_bpnet_1st_conv (Conv1D  (None, 2094, 512)   43520       ['sequence[0][0]']               
 )                                                                                                
                                                                                                  
 wo_bias_bpnet_1conv (Conv1D)   (None, 2090, 512)    786944      ['wo_bias_bpnet_1st_conv[0][0]'] 
                                                                                                  
 wo_bias_bpnet_1crop (Cropping1  (None, 2090, 512)   0           ['wo_bias_bpnet_1st_conv[0][0]'] 
 D)                                                                                               
                                                                                                  
 add (Add)                      (None, 2090, 512)    0           ['wo_bias_bpnet_1conv[0][0]',    
                                                                  'wo_bias_bpnet_1crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_2conv (Conv1D)   (None, 2082, 512)    786944      ['add[0][0]']                    
                                                                                                  
 wo_bias_bpnet_2crop (Cropping1  (None, 2082, 512)   0           ['add[0][0]']                    
 D)                                                                                               
                                                                                                  
 add_1 (Add)                    (None, 2082, 512)    0           ['wo_bias_bpnet_2conv[0][0]',    
                                                                  'wo_bias_bpnet_2crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_3conv (Conv1D)   (None, 2066, 512)    786944      ['add_1[0][0]']                  
                                                                                                  
 wo_bias_bpnet_3crop (Cropping1  (None, 2066, 512)   0           ['add_1[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_2 (Add)                    (None, 2066, 512)    0           ['wo_bias_bpnet_3conv[0][0]',    
                                                                  'wo_bias_bpnet_3crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_4conv (Conv1D)   (None, 2034, 512)    786944      ['add_2[0][0]']                  
                                                                                                  
 wo_bias_bpnet_4crop (Cropping1  (None, 2034, 512)   0           ['add_2[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_3 (Add)                    (None, 2034, 512)    0           ['wo_bias_bpnet_4conv[0][0]',    
                                                                  'wo_bias_bpnet_4crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_5conv (Conv1D)   (None, 1970, 512)    786944      ['add_3[0][0]']                  
                                                                                                  
 wo_bias_bpnet_5crop (Cropping1  (None, 1970, 512)   0           ['add_3[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_4 (Add)                    (None, 1970, 512)    0           ['wo_bias_bpnet_5conv[0][0]',    
                                                                  'wo_bias_bpnet_5crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_6conv (Conv1D)   (None, 1842, 512)    786944      ['add_4[0][0]']                  
                                                                                                  
 wo_bias_bpnet_6crop (Cropping1  (None, 1842, 512)   0           ['add_4[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_5 (Add)                    (None, 1842, 512)    0           ['wo_bias_bpnet_6conv[0][0]',    
                                                                  'wo_bias_bpnet_6crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_7conv (Conv1D)   (None, 1586, 512)    786944      ['add_5[0][0]']                  
                                                                                                  
 wo_bias_bpnet_7crop (Cropping1  (None, 1586, 512)   0           ['add_5[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_6 (Add)                    (None, 1586, 512)    0           ['wo_bias_bpnet_7conv[0][0]',    
                                                                  'wo_bias_bpnet_7crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_8conv (Conv1D)   (None, 1074, 512)    786944      ['add_6[0][0]']                  
                                                                                                  
 wo_bias_bpnet_8crop (Cropping1  (None, 1074, 512)   0           ['add_6[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_7 (Add)                    (None, 1074, 512)    0           ['wo_bias_bpnet_8conv[0][0]',    
                                                                  'wo_bias_bpnet_8crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_prof_out_precrop  (None, 1000, 1)     38401       ['add_7[0][0]']                  
  (Conv1D)                                                                                        
                                                                                                  
 wo_bias_bpnet_logitt_before_fl  (None, 1000, 1)     0           ['wo_bias_bpnet_prof_out_precrop[
 atten (Cropping1D)                                              0][0]']                          
                                                                                                  
 gap (GlobalAveragePooling1D)   (None, 512)          0           ['add_7[0][0]']                  
                                                                                                  
 wo_bias_bpnet_logits_profile_p  (None, 1000)        0           ['wo_bias_bpnet_logitt_before_fla
 redictions (Flatten)                                            tten[0][0]']                     
                                                                                                  
 wo_bias_bpnet_logcount_predict  (None, 1)           513         ['gap[0][0]']                    
 ions (Dense)                                                                                     
                                                                                                  
==================================================================================================
Total params: 6,377,986
Trainable params: 6,377,986
Non-trainable params: 0
__________________________________________________________________________________________________
None
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 model_1 (Functional)           [(None, 1000),       6377986     ['input_1[0][0]',                
                                 (None, 1)]                       'input_2[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 1000)         0           ['model_1[0][0]',                
                                                                  'model_1[0][1]']                
                                                                                                  
 lambda_1 (Lambda)              (None, 1000)         0           ['model_1[1][0]',                
                                                                  'model_1[1][1]']                
                                                                                                  
 lambda_2 (Lambda)              (None, 1000)         0           ['lambda[0][0]',                 
                                                                  'lambda_1[0][0]']               
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 1000, 1)      0           ['lambda_2[0][0]']               
                                                                                                  
 conv1d (Conv1D)                (None, 993, 16)      144         ['tf.expand_dims[0][0]']         
                                                                                                  
 flatten (Flatten)              (None, 15888)        0           ['conv1d[0][0]']                 
                                                                                                  
 dense (Dense)                  (None, 64)           1016896     ['flatten[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 1)            65          ['dense[0][0]']                  
                                                                                                  
==================================================================================================
Total params: 7,395,091
Trainable params: 7,395,091
Non-trainable params: 0
__________________________________________________________________________________________________
None
(135, 2114, 4) (135, 2114, 4) (135,)
LR: 0.0001
Epoch 1/40
2022-09-27 20:34:51.583273: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201
2022-09-27 20:34:53.755833: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
1/7 [===>..........................] - ETA: 1:06 - loss: 0.1080 - root_mean_squared_error: 0.10802/7 [=======>......................] - ETA: 1s - loss: 0.1172 - root_mean_squared_error: 0.1176  3/7 [===========>..................] - ETA: 1s - loss: 0.1287 - root_mean_squared_error: 0.13004/7 [================>.............] - ETA: 0s - loss: 0.1298 - root_mean_squared_error: 0.13075/7 [====================>.........] - ETA: 0s - loss: 0.1325 - root_mean_squared_error: 0.13346/7 [========================>.....] - ETA: 0s - loss: 0.1279 - root_mean_squared_error: 0.12917/7 [==============================] - ETA: 0s - loss: 0.1282 - root_mean_squared_error: 0.1292
Epoch 1: val_loss improved from inf to 0.12582, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.16.8.dense.64.dense.1.rmse
2022-09-27 20:35:05.273329: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
7/7 [==============================] - 21s 2s/step - loss: 0.1282 - root_mean_squared_error: 0.1292 - val_loss: 0.1258 - val_root_mean_squared_error: 0.1268
Epoch 2/40
1/7 [===>..........................] - ETA: 1s - loss: 0.1044 - root_mean_squared_error: 0.10442/7 [=======>......................] - ETA: 1s - loss: 0.0948 - root_mean_squared_error: 0.09533/7 [===========>..................] - ETA: 1s - loss: 0.0992 - root_mean_squared_error: 0.09974/7 [================>.............] - ETA: 0s - loss: 0.1008 - root_mean_squared_error: 0.10125/7 [====================>.........] - ETA: 0s - loss: 0.0969 - root_mean_squared_error: 0.09756/7 [========================>.....] - ETA: 0s - loss: 0.0925 - root_mean_squared_error: 0.09357/7 [==============================] - ETA: 0s - loss: 0.0904 - root_mean_squared_error: 0.0916
Epoch 2: val_loss improved from 0.12582 to 0.12269, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.16.8.dense.64.dense.1.rmse
7/7 [==============================] - 6s 996ms/step - loss: 0.0904 - root_mean_squared_error: 0.0916 - val_loss: 0.1227 - val_root_mean_squared_error: 0.1233
Epoch 3/40
1/7 [===>..........................] - ETA: 2s - loss: 0.0701 - root_mean_squared_error: 0.07012/7 [=======>......................] - ETA: 1s - loss: 0.0682 - root_mean_squared_error: 0.06833/7 [===========>..................] - ETA: 1s - loss: 0.0665 - root_mean_squared_error: 0.06664/7 [================>.............] - ETA: 0s - loss: 0.0771 - root_mean_squared_error: 0.07935/7 [====================>.........] - ETA: 0s - loss: 0.0752 - root_mean_squared_error: 0.07716/7 [========================>.....] - ETA: 0s - loss: 0.0760 - root_mean_squared_error: 0.07767/7 [==============================] - ETA: 0s - loss: 0.0726 - root_mean_squared_error: 0.0747
Epoch 3: val_loss improved from 0.12269 to 0.11427, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.16.8.dense.64.dense.1.rmse
7/7 [==============================] - 6s 1000ms/step - loss: 0.0726 - root_mean_squared_error: 0.0747 - val_loss: 0.1143 - val_root_mean_squared_error: 0.1147
Epoch 4/40
1/7 [===>..........................] - ETA: 2s - loss: 0.0566 - root_mean_squared_error: 0.05662/7 [=======>......................] - ETA: 1s - loss: 0.0566 - root_mean_squared_error: 0.05663/7 [===========>..................] - ETA: 1s - loss: 0.0590 - root_mean_squared_error: 0.05914/7 [================>.............] - ETA: 0s - loss: 0.0547 - root_mean_squared_error: 0.05535/7 [====================>.........] - ETA: 0s - loss: 0.0509 - root_mean_squared_error: 0.05206/7 [========================>.....] - ETA: 0s - loss: 0.0506 - root_mean_squared_error: 0.05157/7 [==============================] - ETA: 0s - loss: 0.0507 - root_mean_squared_error: 0.0515
Epoch 4: val_loss did not improve from 0.11427
7/7 [==============================] - 2s 314ms/step - loss: 0.0507 - root_mean_squared_error: 0.0515 - val_loss: 0.1176 - val_root_mean_squared_error: 0.1180
Epoch 5/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0422 - root_mean_squared_error: 0.04222/7 [=======>......................] - ETA: 1s - loss: 0.0393 - root_mean_squared_error: 0.03943/7 [===========>..................] - ETA: 1s - loss: 0.0342 - root_mean_squared_error: 0.03514/7 [================>.............] - ETA: 0s - loss: 0.0326 - root_mean_squared_error: 0.03345/7 [====================>.........] - ETA: 0s - loss: 0.0356 - root_mean_squared_error: 0.03666/7 [========================>.....] - ETA: 0s - loss: 0.0387 - root_mean_squared_error: 0.04027/7 [==============================] - ETA: 0s - loss: 0.0385 - root_mean_squared_error: 0.0398
Epoch 5: val_loss did not improve from 0.11427
7/7 [==============================] - 2s 316ms/step - loss: 0.0385 - root_mean_squared_error: 0.0398 - val_loss: 0.1260 - val_root_mean_squared_error: 0.1265
Epoch 6/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0283 - root_mean_squared_error: 0.02832/7 [=======>......................] - ETA: 1s - loss: 0.0281 - root_mean_squared_error: 0.02813/7 [===========>..................] - ETA: 1s - loss: 0.0309 - root_mean_squared_error: 0.03114/7 [================>.............] - ETA: 0s - loss: 0.0269 - root_mean_squared_error: 0.02805/7 [====================>.........] - ETA: 0s - loss: 0.0280 - root_mean_squared_error: 0.02896/7 [========================>.....] - ETA: 0s - loss: 0.0323 - root_mean_squared_error: 0.03437/7 [==============================] - ETA: 0s - loss: 0.0326 - root_mean_squared_error: 0.0344
Epoch 6: val_loss did not improve from 0.11427
7/7 [==============================] - 2s 314ms/step - loss: 0.0326 - root_mean_squared_error: 0.0344 - val_loss: 0.1206 - val_root_mean_squared_error: 0.1211
Epoch 7/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0533 - root_mean_squared_error: 0.05332/7 [=======>......................] - ETA: 1s - loss: 0.0460 - root_mean_squared_error: 0.04653/7 [===========>..................] - ETA: 1s - loss: 0.0414 - root_mean_squared_error: 0.04234/7 [================>.............] - ETA: 0s - loss: 0.0385 - root_mean_squared_error: 0.03965/7 [====================>.........] - ETA: 0s - loss: 0.0351 - root_mean_squared_error: 0.03666/7 [========================>.....] - ETA: 0s - loss: 0.0403 - root_mean_squared_error: 0.04327/7 [==============================] - ETA: 0s - loss: 0.0402 - root_mean_squared_error: 0.0427
Epoch 7: val_loss did not improve from 0.11427
7/7 [==============================] - 2s 315ms/step - loss: 0.0402 - root_mean_squared_error: 0.0427 - val_loss: 0.1231 - val_root_mean_squared_error: 0.1235
Epoch 8/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0552 - root_mean_squared_error: 0.05522/7 [=======>......................] - ETA: 1s - loss: 0.0375 - root_mean_squared_error: 0.04153/7 [===========>..................] - ETA: 1s - loss: 0.0396 - root_mean_squared_error: 0.04234/7 [================>.............] - ETA: 0s - loss: 0.0377 - root_mean_squared_error: 0.04005/7 [====================>.........] - ETA: 0s - loss: 0.0375 - root_mean_squared_error: 0.03936/7 [========================>.....] - ETA: 0s - loss: 0.0366 - root_mean_squared_error: 0.03827/7 [==============================] - ETA: 0s - loss: 0.0355 - root_mean_squared_error: 0.0371
Epoch 8: val_loss did not improve from 0.11427
Restoring model weights from the end of the best epoch: 3.
7/7 [==============================] - 2s 322ms/step - loss: 0.0355 - root_mean_squared_error: 0.0371 - val_loss: 0.1175 - val_root_mean_squared_error: 0.1182
Epoch 8: early stopping
TNN loaded from file
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 model_1 (Functional)           [(None, 1000),       6377986     ['input_1[0][0]',                
                                 (None, 1)]                       'input_2[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 1000)         0           ['model_1[0][0]',                
                                                                  'model_1[0][1]']                
                                                                                                  
 lambda_1 (Lambda)              (None, 1000)         0           ['model_1[1][0]',                
                                                                  'model_1[1][1]']                
                                                                                                  
 lambda_2 (Lambda)              (None, 1000)         0           ['lambda[0][0]',                 
                                                                  'lambda_1[0][0]']               
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 1000, 1)      0           ['lambda_2[0][0]']               
                                                                                                  
 conv1d (Conv1D)                (None, 993, 16)      144         ['tf.expand_dims[0][0]']         
                                                                                                  
 flatten (Flatten)              (None, 15888)        0           ['conv1d[0][0]']                 
                                                                                                  
 dense (Dense)                  (None, 64)           1016896     ['flatten[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 1)            65          ['dense[0][0]']                  
                                                                                                  
==================================================================================================
Total params: 7,395,091
Trainable params: 7,395,091
Non-trainable params: 0
__________________________________________________________________________________________________
None
 1/10 [==>...........................] - ETA: 4s 2/10 [=====>........................] - ETA: 0s 3/10 [========>.....................] - ETA: 0s 4/10 [===========>..................] - ETA: 0s 5/10 [==============>...............] - ETA: 0s 6/10 [=================>............] - ETA: 0s 7/10 [====================>.........] - ETA: 0s 8/10 [=======================>......] - ETA: 0s 9/10 [==========================>...] - ETA: 0s10/10 [==============================] - ETA: 0s10/10 [==============================] - 2s 196ms/step
[-0.05273512, -0.10493256, 0.07060971, 0.04090311, -0.2824069, -0.068615235, -0.058691025, 0.014983235, -0.10082715, 0.033196844, -0.031630438, -0.106427714, -0.035103373, -0.1900679, -0.1386808, -0.046620283, -0.12230974, -0.018511526, 0.10393147, 0.023869073, 0.037060056, -0.041211184, 0.07384317, 0.039412823, 0.026012048, 0.02780032, 0.09011425, 0.084245846, -0.09516562, 0.01408233, -0.070181, -0.033334795, -0.0073462254, 0.061128322, 0.05733668, 0.075152665, 0.054918334, -0.018430065, -0.06281963, -0.060143188, -0.033466574, 0.02667813, 0.04817512, -0.09544343, 0.0583389, 0.068271846, 0.02673985, -0.13347451, -0.18238363, -0.063019395, 0.06155244, 0.08816639, 0.054624546, -0.20652036, -0.0025316344, 0.0037624778, 0.07793629, 0.08437214, 0.08982038, -0.046867155, -0.10025726, -0.07054096, -0.036806695, 0.04318082, 0.030251011, 0.03616917, -0.14022802, 0.042297754, -0.08718007, 0.16977723, 0.04659204, 0.10104255, -0.3137507, 0.02175445, -0.08289051, -0.14727041, -0.022915673, 0.052525237, 0.17889477, 0.020284211, -0.09380968, 0.022556327, 0.04196732, 0.08041606, 0.027758265, -0.028117083, -0.068984225, 0.07416454, -0.07229284, 0.07132951, -0.06010909, -0.12512213, 0.021470707, -0.031458903, -0.150461, 0.095575385, -0.028686706, 0.12210334, -0.04408858, -0.016491776, 0.032393023, -0.1272285, -0.013239007, -0.035458878, 0.025879035, -0.15044494, -0.07347122, -0.062387127, 0.067916684, -0.15156177, 0.0100059295, -0.11486562, 0.14306878, 0.047050763, -0.17346708, -0.16188243, -0.1242836, 0.0425798, -0.11040949, 0.07289721, -0.16203316, -0.060536522, -0.013986457, -0.10810024, 0.11303366, 0.12282034, 0.20283519, -0.2442393, 0.106532834, -0.0025370447, 0.16058917, 0.20242816, -0.13265155, -0.056317054, -0.16153356, 0.063379586, 0.1603596, -0.032397028, -0.0885045, -0.11651933, 0.29410437, -0.006730264, -0.15265515, -0.22844714, 0.13520582, -0.21255423, -0.2785207, 0.25241455, -0.37015235, -0.34835654, -0.57369226]
[-0.0905034  -0.09947216  0.07853377  0.07739935 -0.26832333 -0.06778263
 -0.08546479  0.08648197  0.07961277  0.07720217 -0.08014117 -0.08105874
 -0.09328441 -0.09695353 -0.11880182 -0.06326722 -0.08434247 -0.09411035
  0.0921365   0.09063613  0.12313518 -0.07950069  0.09031201  0.0710011
 -0.10043573  0.11124648  0.10079366  0.09531208 -0.06277929 -0.11083511
 -0.10710893 -0.11494793  0.13846627  0.11033365  0.09340035  0.09148435
  0.0829305  -0.06689062 -0.07912685 -0.08899292 -0.09257795  0.0991051
  0.08540135 -0.10334674  0.11694617  0.10851879  0.08058769 -0.12419123
 -0.12557973 -0.06900014  0.15094079  0.14292263  0.11062875 -0.16626157
  0.12909251  0.07481506  0.10535965  0.09083616  0.10223201 -0.07872573
 -0.08115115 -0.10202431  0.1065836   0.10569526  0.09134408 -0.10430546
 -0.11229523  0.08098407 -0.07248487  0.10833224  0.11191964  0.09127144
 -0.34156207  0.16014625 -0.10213176 -0.1030441   0.18302456  0.08710979
  0.16541972  0.15007845 -0.11375303 -0.13332473  0.15195966  0.10983172
 -0.12349412 -0.11492698 -0.15814887  0.08052575 -0.11003885  0.08794768
 -0.10758457 -0.14492674  0.11402104 -0.10341273 -0.11568559  0.11976604
 -0.09906955  0.11174096 -0.11254208 -0.1282223   0.0830264  -0.1545139
 -0.1043491  -0.14034679  0.11594063 -0.13771265 -0.16025063 -0.14683859
  0.1183183  -0.1315937  -0.13619249 -0.12484662  0.15976923  0.10062947
 -0.11664557 -0.1552405  -0.17203074  0.1055946  -0.10456964  0.14444356
 -0.11645929 -0.17384205  0.10422415 -0.12774052  0.12609592  0.12372607
  0.23101375 -0.2028399  -0.22582155  0.17918628  0.12624905  0.20775655
 -0.1733779  -0.18529817 -0.1419532   0.16041179  0.15815749 -0.18451102
 -0.19436191 -0.19201529  0.18251119 -0.17792116 -0.17916801 -0.23552507
  0.18936244 -0.22218015 -0.3508249   0.29389578 -0.33032155 -0.29608878
 -0.52658078]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 151 entries, 0 to 150
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   TNN     151 non-null    float32
 1   Y       151 non-null    float64
dtypes: float32(1), float64(1)
memory usage: 1.9 KB
None
         TNN         Y
0  -0.052735 -0.090503
1  -0.104933 -0.099472
2   0.070610  0.078534
3   0.040903  0.077399
4  -0.282407 -0.268323
5  -0.068615 -0.067783
6  -0.058691 -0.085465
7   0.014983  0.086482
8  -0.100827  0.079613
9   0.033197  0.077202
10 -0.031630 -0.080141
11 -0.106428 -0.081059
12 -0.035103 -0.093284
13 -0.190068 -0.096954
14 -0.138681 -0.118802
15 -0.046620 -0.063267
16 -0.122310 -0.084342
17 -0.018512 -0.094110
18  0.103931  0.092136
19  0.023869  0.090636
1/9 [==>...........................] - ETA: 0s2/9 [=====>........................] - ETA: 0s3/9 [=========>....................] - ETA: 0s4/9 [============>.................] - ETA: 0s5/9 [===============>..............] - ETA: 0s6/9 [===================>..........] - ETA: 0s7/9 [======================>.......] - ETA: 0s8/9 [=========================>....] - ETA: 0s9/9 [==============================] - ETA: 0s9/9 [==============================] - 1s 87ms/step
[-0.12230974, 0.037060056, -0.063019395, 0.042297754, 0.29410437, -0.07347122, -0.068984225, -0.06281963, -0.15044494, -0.060143188, -0.04408858, -0.22844714, -0.062387127, 0.08816639, -0.150461, -0.11486562, 0.054624546, -0.028686706, 0.030251011, 0.04090311, 0.08982038, 0.032393023, -0.16203316, -0.035103373, 0.075152665, -0.09380968, 0.07384317, -0.18238363, 0.061128322, 0.20283519, -0.15156177, 0.033196844, 0.10393147, -0.3137507, 0.1603596, -0.018511526, -0.106427714, 0.13520582, 0.047050763, -0.060536522, -0.2824069, 0.12210334, -0.05273512, -0.10025726, 0.052525237, 0.07416454, 0.07793629, -0.006730264, -0.033466574, -0.09516562, 0.02780032, 0.023869073, -0.046620283, -0.041211184, 0.11303366, 0.12282034, -0.09544343, 0.02673985, 0.06155244, -0.068615235, -0.16188243, -0.12512213, 0.0425798, -0.57369226, -0.08289051, 0.20242816, 0.0583389, 0.08437214, 0.063379586, 0.04817512, -0.2442393, -0.13265155, 0.16977723, 0.0100059295, -0.06010909, 0.08041606, -0.20652036, 0.067916684, 0.084245846, 0.09011425, 0.07060971, 0.068271846, 0.05733668, 0.07289721, 0.10104255, -0.08718007, 0.02667813, 0.04318082, -0.14022802, -0.13347451, 0.17889477, -0.07054096, -0.34835654, -0.21255423, -0.070181, -0.1386808, -0.37015235, -0.016491776, -0.15265515, 0.07132951, 0.021470707, -0.07229284, 0.14306878, 0.16058917, -0.17346708, -0.10493256, -0.046867155, -0.16153356, -0.14727041, -0.0073462254, -0.1242836, 0.01408233, -0.0025316344, 0.106532834, 0.039412823, -0.035458878, 0.027758265, -0.1900679, 0.04659204, -0.058691025, 0.054918334, 0.25241455, 0.020284211, -0.018430065, -0.031630438, -0.036806695, -0.013239007, 0.022556327, 0.03616917, -0.11040949, 0.0037624778, 0.025879035, -0.031458903, -0.056317054, -0.11651933]
[-0.08434247  0.12313518 -0.06900014  0.08098407  0.18251119 -0.16025063
 -0.15814887 -0.07912685 -0.13771265 -0.08899292 -0.11254208 -0.23552507
 -0.14683859  0.14292263 -0.11568559 -0.12484662  0.11062875 -0.09906955
  0.09134408  0.07739935  0.10223201  0.0830264  -0.11645929 -0.09328441
  0.09148435 -0.11375303  0.09031201 -0.12557973  0.11033365  0.23101375
 -0.1315937   0.07720217  0.0921365  -0.34156207  0.15815749 -0.09411035
 -0.08105874  0.18936244  0.10062947 -0.17384205 -0.26832333  0.11174096
 -0.0905034  -0.08115115  0.08710979  0.08052575  0.10535965 -0.17792116
 -0.09257795 -0.06277929  0.11124648  0.09063613 -0.06326722 -0.07950069
  0.12609592  0.12372607 -0.10334674  0.08058769  0.15094079 -0.06778263
 -0.1552405  -0.14492674  0.1055946  -0.52658078 -0.10213176  0.20775655
  0.11694617  0.09083616  0.16041179  0.08540135 -0.2028399  -0.1733779
  0.10833224 -0.13619249 -0.10758457  0.10983172 -0.16626157  0.1183183
  0.09531208  0.10079366  0.07853377  0.10851879  0.09340035  0.14444356
  0.09127144 -0.07248487  0.0991051   0.10569526 -0.11229523 -0.12419123
  0.16541972 -0.10202431 -0.29608878 -0.22218015 -0.10710893 -0.11880182
 -0.33032155 -0.1282223  -0.17916801  0.08794768  0.11402104 -0.11003885
  0.15976923  0.12624905 -0.11664557 -0.09947216 -0.07872573 -0.1419532
 -0.1030441   0.13846627 -0.17203074 -0.11083511  0.12909251 -0.22582155
  0.0710011  -0.14034679 -0.12349412 -0.09695353  0.11191964 -0.08546479
  0.0829305   0.29389578  0.15007845 -0.06689062 -0.08014117  0.1065836
 -0.1043491  -0.13332473 -0.10430546 -0.10456964  0.07481506  0.11594063
 -0.10341273 -0.18529817 -0.19201529]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 135 entries, 0 to 134
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   TNN     135 non-null    float32
 1   Y       135 non-null    float64
dtypes: float32(1), float64(1)
memory usage: 1.7 KB
None
         TNN         Y
0  -0.122310 -0.084342
1   0.037060  0.123135
2  -0.063019 -0.069000
3   0.042298  0.080984
4   0.294104  0.182511
5  -0.073471 -0.160251
6  -0.068984 -0.158149
7  -0.062820 -0.079127
8  -0.150445 -0.137713
9  -0.060143 -0.088993
10 -0.044089 -0.112542
11 -0.228447 -0.235525
12 -0.062387 -0.146839
13  0.088166  0.142923
14 -0.150461 -0.115686
15 -0.114866 -0.124847
16  0.054625  0.110629
17 -0.028687 -0.099070
18  0.030251  0.091344
19  0.040903  0.077399
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 388ms/step
[0.014983235, -0.022915673, -0.032397028, -0.2785207, -0.0025370447, -0.033334795, 0.095575385, 0.04196732, 0.02175445, 0.026012048, -0.028117083, -0.0885045, -0.10082715, -0.10810024, -0.013986457, -0.1272285]
[ 0.08648197  0.18302456 -0.18451102 -0.3508249   0.17918628 -0.11494793
  0.11976604  0.15195966  0.16014625 -0.10043573 -0.11492698 -0.19436191
  0.07961277 -0.12774052  0.10422415 -0.1545139 ]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 16 entries, 0 to 15
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   TNN     16 non-null     float32
 1   Y       16 non-null     float64
dtypes: float32(1), float64(1)
memory usage: 320.0 bytes
None
         TNN         Y
0   0.014983  0.086482
1  -0.022916  0.183025
2  -0.032397 -0.184511
3  -0.278521 -0.350825
4  -0.002537  0.179186
5  -0.033335 -0.114948
6   0.095575  0.119766
7   0.041967  0.151960
8   0.021754  0.160146
9   0.026012 -0.100436
10 -0.028117 -0.114927
11 -0.088505 -0.194362
12 -0.100827  0.079613
13 -0.108100 -0.127741
14 -0.013986  0.104224
15 -0.127228 -0.154514
spearman TNN-all: 0.7915998605785988
pearson TNN-all: 0.8473057024702271
spearman TNN-train: 0.81438396254024
pearson TNN-train: 0.8714538780520255
spearman TNN-test: 0.7264705882352941
pearson TNN-test: 0.7135569738943557
