2022-09-27 20:32:43.546528: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-27 20:32:46.592374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9653 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5
2022-09-27 20:32:46.595798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9653 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:60:00.0, compute capability: 7.5
2022-09-27 20:32:46.597792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9653 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b1:00.0, compute capability: 7.5
2022-09-27 20:32:46.599594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 9653 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:da:00.0, compute capability: 7.5
WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.
here
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 sequence (InputLayer)          [(None, 2114, 4)]    0           []                               
                                                                                                  
 wo_bias_bpnet_1st_conv (Conv1D  (None, 2094, 512)   43520       ['sequence[0][0]']               
 )                                                                                                
                                                                                                  
 wo_bias_bpnet_1conv (Conv1D)   (None, 2090, 512)    786944      ['wo_bias_bpnet_1st_conv[0][0]'] 
                                                                                                  
 wo_bias_bpnet_1crop (Cropping1  (None, 2090, 512)   0           ['wo_bias_bpnet_1st_conv[0][0]'] 
 D)                                                                                               
                                                                                                  
 add (Add)                      (None, 2090, 512)    0           ['wo_bias_bpnet_1conv[0][0]',    
                                                                  'wo_bias_bpnet_1crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_2conv (Conv1D)   (None, 2082, 512)    786944      ['add[0][0]']                    
                                                                                                  
 wo_bias_bpnet_2crop (Cropping1  (None, 2082, 512)   0           ['add[0][0]']                    
 D)                                                                                               
                                                                                                  
 add_1 (Add)                    (None, 2082, 512)    0           ['wo_bias_bpnet_2conv[0][0]',    
                                                                  'wo_bias_bpnet_2crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_3conv (Conv1D)   (None, 2066, 512)    786944      ['add_1[0][0]']                  
                                                                                                  
 wo_bias_bpnet_3crop (Cropping1  (None, 2066, 512)   0           ['add_1[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_2 (Add)                    (None, 2066, 512)    0           ['wo_bias_bpnet_3conv[0][0]',    
                                                                  'wo_bias_bpnet_3crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_4conv (Conv1D)   (None, 2034, 512)    786944      ['add_2[0][0]']                  
                                                                                                  
 wo_bias_bpnet_4crop (Cropping1  (None, 2034, 512)   0           ['add_2[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_3 (Add)                    (None, 2034, 512)    0           ['wo_bias_bpnet_4conv[0][0]',    
                                                                  'wo_bias_bpnet_4crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_5conv (Conv1D)   (None, 1970, 512)    786944      ['add_3[0][0]']                  
                                                                                                  
 wo_bias_bpnet_5crop (Cropping1  (None, 1970, 512)   0           ['add_3[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_4 (Add)                    (None, 1970, 512)    0           ['wo_bias_bpnet_5conv[0][0]',    
                                                                  'wo_bias_bpnet_5crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_6conv (Conv1D)   (None, 1842, 512)    786944      ['add_4[0][0]']                  
                                                                                                  
 wo_bias_bpnet_6crop (Cropping1  (None, 1842, 512)   0           ['add_4[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_5 (Add)                    (None, 1842, 512)    0           ['wo_bias_bpnet_6conv[0][0]',    
                                                                  'wo_bias_bpnet_6crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_7conv (Conv1D)   (None, 1586, 512)    786944      ['add_5[0][0]']                  
                                                                                                  
 wo_bias_bpnet_7crop (Cropping1  (None, 1586, 512)   0           ['add_5[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_6 (Add)                    (None, 1586, 512)    0           ['wo_bias_bpnet_7conv[0][0]',    
                                                                  'wo_bias_bpnet_7crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_8conv (Conv1D)   (None, 1074, 512)    786944      ['add_6[0][0]']                  
                                                                                                  
 wo_bias_bpnet_8crop (Cropping1  (None, 1074, 512)   0           ['add_6[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_7 (Add)                    (None, 1074, 512)    0           ['wo_bias_bpnet_8conv[0][0]',    
                                                                  'wo_bias_bpnet_8crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_prof_out_precrop  (None, 1000, 1)     38401       ['add_7[0][0]']                  
  (Conv1D)                                                                                        
                                                                                                  
 wo_bias_bpnet_logitt_before_fl  (None, 1000, 1)     0           ['wo_bias_bpnet_prof_out_precrop[
 atten (Cropping1D)                                              0][0]']                          
                                                                                                  
 gap (GlobalAveragePooling1D)   (None, 512)          0           ['add_7[0][0]']                  
                                                                                                  
 wo_bias_bpnet_logits_profile_p  (None, 1000)        0           ['wo_bias_bpnet_logitt_before_fla
 redictions (Flatten)                                            tten[0][0]']                     
                                                                                                  
 wo_bias_bpnet_logcount_predict  (None, 1)           513         ['gap[0][0]']                    
 ions (Dense)                                                                                     
                                                                                                  
==================================================================================================
Total params: 6,377,986
Trainable params: 6,377,986
Non-trainable params: 0
__________________________________________________________________________________________________
None
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 model_1 (Functional)           [(None, 1000),       6377986     ['input_1[0][0]',                
                                 (None, 1)]                       'input_2[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 1000)         0           ['model_1[0][0]',                
                                                                  'model_1[0][1]']                
                                                                                                  
 lambda_1 (Lambda)              (None, 1000)         0           ['model_1[1][0]',                
                                                                  'model_1[1][1]']                
                                                                                                  
 lambda_2 (Lambda)              (None, 1000)         0           ['lambda[0][0]',                 
                                                                  'lambda_1[0][0]']               
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 1000, 1)      0           ['lambda_2[0][0]']               
                                                                                                  
 conv1d (Conv1D)                (None, 998, 32)      128         ['tf.expand_dims[0][0]']         
                                                                                                  
 flatten (Flatten)              (None, 31936)        0           ['conv1d[0][0]']                 
                                                                                                  
 dense (Dense)                  (None, 64)           2043968     ['flatten[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 1)            65          ['dense[0][0]']                  
                                                                                                  
==================================================================================================
Total params: 8,422,147
Trainable params: 8,422,147
Non-trainable params: 0
__________________________________________________________________________________________________
None
(135, 2114, 4) (135, 2114, 4) (135,)
LR: 0.0001
Epoch 1/40
2022-09-27 20:32:51.629187: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201
2022-09-27 20:32:53.692313: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
1/7 [===>..........................] - ETA: 1:05 - loss: 0.1188 - root_mean_squared_error: 0.11882/7 [=======>......................] - ETA: 1s - loss: 0.1271 - root_mean_squared_error: 0.1274  3/7 [===========>..................] - ETA: 1s - loss: 0.1312 - root_mean_squared_error: 0.13154/7 [================>.............] - ETA: 0s - loss: 0.1355 - root_mean_squared_error: 0.13595/7 [====================>.........] - ETA: 0s - loss: 0.1298 - root_mean_squared_error: 0.13076/7 [========================>.....] - ETA: 0s - loss: 0.1276 - root_mean_squared_error: 0.12857/7 [==============================] - ETA: 0s - loss: 0.1275 - root_mean_squared_error: 0.1282
Epoch 1: val_loss improved from inf to 0.12276, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.32.3.dense.64.dense.1.rmse
2022-09-27 20:33:04.605637: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
7/7 [==============================] - 20s 2s/step - loss: 0.1275 - root_mean_squared_error: 0.1282 - val_loss: 0.1228 - val_root_mean_squared_error: 0.1238
Epoch 2/40
1/7 [===>..........................] - ETA: 2s - loss: 0.1333 - root_mean_squared_error: 0.13332/7 [=======>......................] - ETA: 1s - loss: 0.1192 - root_mean_squared_error: 0.12003/7 [===========>..................] - ETA: 1s - loss: 0.1120 - root_mean_squared_error: 0.11314/7 [================>.............] - ETA: 0s - loss: 0.1083 - root_mean_squared_error: 0.10935/7 [====================>.........] - ETA: 0s - loss: 0.1021 - root_mean_squared_error: 0.10376/7 [========================>.....] - ETA: 0s - loss: 0.0974 - root_mean_squared_error: 0.09947/7 [==============================] - ETA: 0s - loss: 0.0953 - root_mean_squared_error: 0.0973
Epoch 2: val_loss did not improve from 0.12276
7/7 [==============================] - 2s 343ms/step - loss: 0.0953 - root_mean_squared_error: 0.0973 - val_loss: 0.1270 - val_root_mean_squared_error: 0.1276
Epoch 3/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0926 - root_mean_squared_error: 0.09262/7 [=======>......................] - ETA: 1s - loss: 0.0730 - root_mean_squared_error: 0.07563/7 [===========>..................] - ETA: 1s - loss: 0.0704 - root_mean_squared_error: 0.07234/7 [================>.............] - ETA: 0s - loss: 0.0666 - root_mean_squared_error: 0.06845/7 [====================>.........] - ETA: 0s - loss: 0.0680 - root_mean_squared_error: 0.06956/7 [========================>.....] - ETA: 0s - loss: 0.0686 - root_mean_squared_error: 0.06997/7 [==============================] - ETA: 0s - loss: 0.0674 - root_mean_squared_error: 0.0686
Epoch 3: val_loss did not improve from 0.12276
7/7 [==============================] - 2s 342ms/step - loss: 0.0674 - root_mean_squared_error: 0.0686 - val_loss: 0.1267 - val_root_mean_squared_error: 0.1274
Epoch 4/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0544 - root_mean_squared_error: 0.05442/7 [=======>......................] - ETA: 1s - loss: 0.0506 - root_mean_squared_error: 0.05083/7 [===========>..................] - ETA: 1s - loss: 0.0487 - root_mean_squared_error: 0.04884/7 [================>.............] - ETA: 0s - loss: 0.0503 - root_mean_squared_error: 0.05055/7 [====================>.........] - ETA: 0s - loss: 0.0489 - root_mean_squared_error: 0.04926/7 [========================>.....] - ETA: 0s - loss: 0.0489 - root_mean_squared_error: 0.04917/7 [==============================] - ETA: 0s - loss: 0.0487 - root_mean_squared_error: 0.0488
Epoch 4: val_loss did not improve from 0.12276
7/7 [==============================] - 2s 342ms/step - loss: 0.0487 - root_mean_squared_error: 0.0488 - val_loss: 0.1315 - val_root_mean_squared_error: 0.1325
Epoch 5/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0294 - root_mean_squared_error: 0.02942/7 [=======>......................] - ETA: 1s - loss: 0.0388 - root_mean_squared_error: 0.03993/7 [===========>..................] - ETA: 1s - loss: 0.0325 - root_mean_squared_error: 0.03464/7 [================>.............] - ETA: 0s - loss: 0.0325 - root_mean_squared_error: 0.03415/7 [====================>.........] - ETA: 0s - loss: 0.0349 - root_mean_squared_error: 0.03646/7 [========================>.....] - ETA: 0s - loss: 0.0366 - root_mean_squared_error: 0.03807/7 [==============================] - ETA: 0s - loss: 0.0364 - root_mean_squared_error: 0.0376
Epoch 5: val_loss did not improve from 0.12276
7/7 [==============================] - 2s 343ms/step - loss: 0.0364 - root_mean_squared_error: 0.0376 - val_loss: 0.1405 - val_root_mean_squared_error: 0.1418
Epoch 6/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0216 - root_mean_squared_error: 0.02162/7 [=======>......................] - ETA: 1s - loss: 0.0304 - root_mean_squared_error: 0.03163/7 [===========>..................] - ETA: 1s - loss: 0.0317 - root_mean_squared_error: 0.03254/7 [================>.............] - ETA: 0s - loss: 0.0295 - root_mean_squared_error: 0.03045/7 [====================>.........] - ETA: 0s - loss: 0.0294 - root_mean_squared_error: 0.03026/7 [========================>.....] - ETA: 0s - loss: 0.0283 - root_mean_squared_error: 0.02907/7 [==============================] - ETA: 0s - loss: 0.0301 - root_mean_squared_error: 0.0312
Epoch 6: val_loss did not improve from 0.12276
Restoring model weights from the end of the best epoch: 1.
7/7 [==============================] - 2s 349ms/step - loss: 0.0301 - root_mean_squared_error: 0.0312 - val_loss: 0.1361 - val_root_mean_squared_error: 0.1373
Epoch 6: early stopping
TNN loaded from file
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 model_1 (Functional)           [(None, 1000),       6377986     ['input_1[0][0]',                
                                 (None, 1)]                       'input_2[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 1000)         0           ['model_1[0][0]',                
                                                                  'model_1[0][1]']                
                                                                                                  
 lambda_1 (Lambda)              (None, 1000)         0           ['model_1[1][0]',                
                                                                  'model_1[1][1]']                
                                                                                                  
 lambda_2 (Lambda)              (None, 1000)         0           ['lambda[0][0]',                 
                                                                  'lambda_1[0][0]']               
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 1000, 1)      0           ['lambda_2[0][0]']               
                                                                                                  
 conv1d (Conv1D)                (None, 998, 32)      128         ['tf.expand_dims[0][0]']         
                                                                                                  
 flatten (Flatten)              (None, 31936)        0           ['conv1d[0][0]']                 
                                                                                                  
 dense (Dense)                  (None, 64)           2043968     ['flatten[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 1)            65          ['dense[0][0]']                  
                                                                                                  
==================================================================================================
Total params: 8,422,147
Trainable params: 8,422,147
Non-trainable params: 0
__________________________________________________________________________________________________
None
 1/10 [==>...........................] - ETA: 4s 2/10 [=====>........................] - ETA: 0s 3/10 [========>.....................] - ETA: 0s 4/10 [===========>..................] - ETA: 0s 5/10 [==============>...............] - ETA: 0s 6/10 [=================>............] - ETA: 0s 7/10 [====================>.........] - ETA: 0s 8/10 [=======================>......] - ETA: 0s 9/10 [==========================>...] - ETA: 0s10/10 [==============================] - ETA: 0s10/10 [==============================] - 2s 213ms/step
[-0.010579838, -0.03503379, 0.0031322972, -0.07750412, -0.09384749, -0.04876622, -0.08850418, -0.0033843124, -0.109218866, -0.062966615, -0.038880724, -0.06366728, 0.010927112, -0.22169574, -0.06526117, -0.014075403, -0.043363675, -0.016757324, 0.04867006, -0.041633617, -0.013406461, -0.03956156, 0.0571409, 0.00413346, 0.014055267, -0.09898872, -0.04678163, 0.065774105, -0.099614285, -0.008961949, -0.023859713, -0.024331857, -0.033396557, -0.008372147, 0.010748032, 0.023051908, -0.052838802, -0.019930584, -0.036443543, -0.009194659, -0.011191784, -0.011115802, 0.0154829705, -0.03981854, 0.011807086, -0.037129242, -0.0043696943, -0.065723516, -0.10175023, -0.015460526, 0.010542899, 0.0074596675, 0.031470608, -0.15142095, -0.0040703174, -0.0042916276, 0.023601009, 0.029908448, 0.038103875, -0.062059924, -0.12187443, -0.026802579, -0.053744245, -0.0066268733, 0.010902257, 0.031710878, -0.12268102, -0.062342566, -0.109968774, 0.13339683, 0.0044529648, 0.06926634, -0.595473, 0.0053894604, -0.0724432, -0.2524054, -0.060168345, -0.014430483, 0.03872176, -0.0076019773, -0.046579257, 0.0042958297, 0.022719614, 0.023277856, 0.018660048, -0.09819901, -0.040185817, -0.013482118, -0.03147567, 0.044917725, -0.050649617, -0.06454213, 0.26185945, -0.029990545, -0.10776732, 0.05695488, -0.22888206, 0.006670978, -0.023705937, -0.0103147365, 0.0038008238, -0.15254106, -0.020638427, -0.04040485, 0.019159814, -0.26867974, 0.0014118857, -0.019988803, -0.022927798, -0.3038372, 0.01741696, -0.339967, 0.008865687, 0.0077705258, -0.17492451, -0.21814486, -0.12714668, -0.0011678207, -0.15780932, 0.029970625, -0.09044774, -0.041353583, -0.01694747, -0.12514794, 0.009893226, 0.108852886, -0.013684498, -0.22165316, 0.08592732, -0.009411929, 0.08616162, 0.114044994, -0.06956491, -0.068425044, -0.049270775, -0.001133786, 0.08564428, -0.051958624, -0.07316133, -0.10155426, 0.2520819, 0.015814537, -0.053278767, -0.25734872, 0.042923905, -0.10107509, -0.34790003, 0.1944514, -0.40497196, -0.31515795, -0.68083656]
[-0.0905034  -0.09947216  0.07853377  0.07739935 -0.26832333 -0.06778263
 -0.08546479  0.08648197  0.07961277  0.07720217 -0.08014117 -0.08105874
 -0.09328441 -0.09695353 -0.11880182 -0.06326722 -0.08434247 -0.09411035
  0.0921365   0.09063613  0.12313518 -0.07950069  0.09031201  0.0710011
 -0.10043573  0.11124648  0.10079366  0.09531208 -0.06277929 -0.11083511
 -0.10710893 -0.11494793  0.13846627  0.11033365  0.09340035  0.09148435
  0.0829305  -0.06689062 -0.07912685 -0.08899292 -0.09257795  0.0991051
  0.08540135 -0.10334674  0.11694617  0.10851879  0.08058769 -0.12419123
 -0.12557973 -0.06900014  0.15094079  0.14292263  0.11062875 -0.16626157
  0.12909251  0.07481506  0.10535965  0.09083616  0.10223201 -0.07872573
 -0.08115115 -0.10202431  0.1065836   0.10569526  0.09134408 -0.10430546
 -0.11229523  0.08098407 -0.07248487  0.10833224  0.11191964  0.09127144
 -0.34156207  0.16014625 -0.10213176 -0.1030441   0.18302456  0.08710979
  0.16541972  0.15007845 -0.11375303 -0.13332473  0.15195966  0.10983172
 -0.12349412 -0.11492698 -0.15814887  0.08052575 -0.11003885  0.08794768
 -0.10758457 -0.14492674  0.11402104 -0.10341273 -0.11568559  0.11976604
 -0.09906955  0.11174096 -0.11254208 -0.1282223   0.0830264  -0.1545139
 -0.1043491  -0.14034679  0.11594063 -0.13771265 -0.16025063 -0.14683859
  0.1183183  -0.1315937  -0.13619249 -0.12484662  0.15976923  0.10062947
 -0.11664557 -0.1552405  -0.17203074  0.1055946  -0.10456964  0.14444356
 -0.11645929 -0.17384205  0.10422415 -0.12774052  0.12609592  0.12372607
  0.23101375 -0.2028399  -0.22582155  0.17918628  0.12624905  0.20775655
 -0.1733779  -0.18529817 -0.1419532   0.16041179  0.15815749 -0.18451102
 -0.19436191 -0.19201529  0.18251119 -0.17792116 -0.17916801 -0.23552507
  0.18936244 -0.22218015 -0.3508249   0.29389578 -0.33032155 -0.29608878
 -0.52658078]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 151 entries, 0 to 150
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   TNN     151 non-null    float32
 1   Y       151 non-null    float64
dtypes: float32(1), float64(1)
memory usage: 1.9 KB
None
         TNN         Y
0  -0.010580 -0.090503
1  -0.035034 -0.099472
2   0.003132  0.078534
3  -0.077504  0.077399
4  -0.093847 -0.268323
5  -0.048766 -0.067783
6  -0.088504 -0.085465
7  -0.003384  0.086482
8  -0.109219  0.079613
9  -0.062967  0.077202
10 -0.038881 -0.080141
11 -0.063667 -0.081059
12  0.010927 -0.093284
13 -0.221696 -0.096954
14 -0.065261 -0.118802
15 -0.014075 -0.063267
16 -0.043364 -0.084342
17 -0.016757 -0.094110
18  0.048670  0.092136
19 -0.041634  0.090636
1/9 [==>...........................] - ETA: 0s2/9 [=====>........................] - ETA: 0s3/9 [=========>....................] - ETA: 0s4/9 [============>.................] - ETA: 0s5/9 [===============>..............] - ETA: 0s6/9 [===================>..........] - ETA: 0s7/9 [======================>.......] - ETA: 0s8/9 [=========================>....] - ETA: 0s9/9 [==============================] - ETA: 0s9/9 [==============================] - 1s 95ms/step
[-0.043363675, -0.013406461, -0.015460526, -0.062342566, 0.2520819, 0.0014118857, -0.040185817, -0.036443543, -0.26867974, -0.009194659, -0.023705937, -0.25734872, -0.019988803, 0.0074596675, -0.10776732, -0.339967, 0.031470608, -0.22888206, 0.010902257, -0.07750412, 0.038103875, 0.0038008238, -0.09044774, 0.010927112, 0.023051908, -0.046579257, 0.0571409, -0.10175023, -0.008372147, -0.013684498, -0.3038372, -0.062966615, 0.04867006, -0.595473, 0.08564428, -0.016757324, -0.06366728, 0.042923905, 0.0077705258, -0.041353583, -0.09384749, 0.006670978, -0.010579838, -0.12187443, -0.014430483, -0.013482118, 0.023601009, 0.015814537, -0.011191784, -0.099614285, -0.09898872, -0.041633617, -0.014075403, -0.03956156, 0.009893226, 0.108852886, -0.03981854, -0.0043696943, 0.010542899, -0.04876622, -0.21814486, -0.06454213, -0.0011678207, -0.68083656, -0.0724432, 0.114044994, 0.011807086, 0.029908448, -0.001133786, 0.0154829705, -0.22165316, -0.06956491, 0.13339683, 0.01741696, -0.050649617, 0.023277856, -0.15142095, -0.022927798, 0.065774105, -0.04678163, 0.0031322972, -0.037129242, 0.010748032, 0.029970625, 0.06926634, -0.109968774, -0.011115802, -0.0066268733, -0.12268102, -0.065723516, 0.03872176, -0.026802579, -0.31515795, -0.10107509, -0.023859713, -0.06526117, -0.40497196, -0.0103147365, -0.053278767, 0.044917725, 0.26185945, -0.03147567, 0.008865687, 0.08616162, -0.17492451, -0.03503379, -0.062059924, -0.049270775, -0.2524054, -0.033396557, -0.12714668, -0.008961949, -0.0040703174, 0.08592732, 0.00413346, -0.04040485, 0.018660048, -0.22169574, 0.0044529648, -0.08850418, -0.052838802, 0.1944514, -0.0076019773, -0.019930584, -0.038880724, -0.053744245, -0.020638427, 0.0042958297, 0.031710878, -0.15780932, -0.0042916276, 0.019159814, -0.029990545, -0.068425044, -0.10155426]
[-0.08434247  0.12313518 -0.06900014  0.08098407  0.18251119 -0.16025063
 -0.15814887 -0.07912685 -0.13771265 -0.08899292 -0.11254208 -0.23552507
 -0.14683859  0.14292263 -0.11568559 -0.12484662  0.11062875 -0.09906955
  0.09134408  0.07739935  0.10223201  0.0830264  -0.11645929 -0.09328441
  0.09148435 -0.11375303  0.09031201 -0.12557973  0.11033365  0.23101375
 -0.1315937   0.07720217  0.0921365  -0.34156207  0.15815749 -0.09411035
 -0.08105874  0.18936244  0.10062947 -0.17384205 -0.26832333  0.11174096
 -0.0905034  -0.08115115  0.08710979  0.08052575  0.10535965 -0.17792116
 -0.09257795 -0.06277929  0.11124648  0.09063613 -0.06326722 -0.07950069
  0.12609592  0.12372607 -0.10334674  0.08058769  0.15094079 -0.06778263
 -0.1552405  -0.14492674  0.1055946  -0.52658078 -0.10213176  0.20775655
  0.11694617  0.09083616  0.16041179  0.08540135 -0.2028399  -0.1733779
  0.10833224 -0.13619249 -0.10758457  0.10983172 -0.16626157  0.1183183
  0.09531208  0.10079366  0.07853377  0.10851879  0.09340035  0.14444356
  0.09127144 -0.07248487  0.0991051   0.10569526 -0.11229523 -0.12419123
  0.16541972 -0.10202431 -0.29608878 -0.22218015 -0.10710893 -0.11880182
 -0.33032155 -0.1282223  -0.17916801  0.08794768  0.11402104 -0.11003885
  0.15976923  0.12624905 -0.11664557 -0.09947216 -0.07872573 -0.1419532
 -0.1030441   0.13846627 -0.17203074 -0.11083511  0.12909251 -0.22582155
  0.0710011  -0.14034679 -0.12349412 -0.09695353  0.11191964 -0.08546479
  0.0829305   0.29389578  0.15007845 -0.06689062 -0.08014117  0.1065836
 -0.1043491  -0.13332473 -0.10430546 -0.10456964  0.07481506  0.11594063
 -0.10341273 -0.18529817 -0.19201529]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 135 entries, 0 to 134
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   TNN     135 non-null    float32
 1   Y       135 non-null    float64
dtypes: float32(1), float64(1)
memory usage: 1.7 KB
None
         TNN         Y
0  -0.043364 -0.084342
1  -0.013406  0.123135
2  -0.015461 -0.069000
3  -0.062343  0.080984
4   0.252082  0.182511
5   0.001412 -0.160251
6  -0.040186 -0.158149
7  -0.036444 -0.079127
8  -0.268680 -0.137713
9  -0.009195 -0.088993
10 -0.023706 -0.112542
11 -0.257349 -0.235525
12 -0.019989 -0.146839
13  0.007460  0.142923
14 -0.107767 -0.115686
15 -0.339967 -0.124847
16  0.031471  0.110629
17 -0.228882 -0.099070
18  0.010902  0.091344
19 -0.077504  0.077399
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 396ms/step
[-0.0033843124, -0.060168345, -0.051958624, -0.34790003, -0.009411929, -0.024331857, 0.05695488, 0.022719614, 0.0053894604, 0.014055267, -0.09819901, -0.07316133, -0.109218866, -0.12514794, -0.01694747, -0.15254106]
[ 0.08648197  0.18302456 -0.18451102 -0.3508249   0.17918628 -0.11494793
  0.11976604  0.15195966  0.16014625 -0.10043573 -0.11492698 -0.19436191
  0.07961277 -0.12774052  0.10422415 -0.1545139 ]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 16 entries, 0 to 15
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   TNN     16 non-null     float32
 1   Y       16 non-null     float64
dtypes: float32(1), float64(1)
memory usage: 320.0 bytes
None
         TNN         Y
0  -0.003384  0.086482
1  -0.060168  0.183025
2  -0.051959 -0.184511
3  -0.347900 -0.350825
4  -0.009412  0.179186
5  -0.024332 -0.114948
6   0.056955  0.119766
7   0.022720  0.151960
8   0.005389  0.160146
9   0.014055 -0.100436
10 -0.098199 -0.114927
11 -0.073161 -0.194362
12 -0.109219  0.079613
13 -0.125148 -0.127741
14 -0.016947  0.104224
15 -0.152541 -0.154514
spearman TNN-all: 0.6423945625653538
pearson TNN-all: 0.6743870329905528
spearman TNN-train: 0.6430689688810849
pearson TNN-train: 0.6783975905977063
spearman TNN-test: 0.6382352941176471
pearson TNN-test: 0.698845962335885
