2022-09-27 20:39:43.373219: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-27 20:39:46.381560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22846 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:1b:00.0, compute capability: 7.5
2022-09-27 20:39:46.385051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22846 MB memory:  -> device: 1, name: NVIDIA TITAN RTX, pci bus id: 0000:61:00.0, compute capability: 7.5
2022-09-27 20:39:46.387045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22846 MB memory:  -> device: 2, name: NVIDIA TITAN RTX, pci bus id: 0000:b2:00.0, compute capability: 7.5
2022-09-27 20:39:46.388954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22846 MB memory:  -> device: 3, name: NVIDIA TITAN RTX, pci bus id: 0000:db:00.0, compute capability: 7.5
WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.
here
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 sequence (InputLayer)          [(None, 2114, 4)]    0           []                               
                                                                                                  
 wo_bias_bpnet_1st_conv (Conv1D  (None, 2094, 512)   43520       ['sequence[0][0]']               
 )                                                                                                
                                                                                                  
 wo_bias_bpnet_1conv (Conv1D)   (None, 2090, 512)    786944      ['wo_bias_bpnet_1st_conv[0][0]'] 
                                                                                                  
 wo_bias_bpnet_1crop (Cropping1  (None, 2090, 512)   0           ['wo_bias_bpnet_1st_conv[0][0]'] 
 D)                                                                                               
                                                                                                  
 add (Add)                      (None, 2090, 512)    0           ['wo_bias_bpnet_1conv[0][0]',    
                                                                  'wo_bias_bpnet_1crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_2conv (Conv1D)   (None, 2082, 512)    786944      ['add[0][0]']                    
                                                                                                  
 wo_bias_bpnet_2crop (Cropping1  (None, 2082, 512)   0           ['add[0][0]']                    
 D)                                                                                               
                                                                                                  
 add_1 (Add)                    (None, 2082, 512)    0           ['wo_bias_bpnet_2conv[0][0]',    
                                                                  'wo_bias_bpnet_2crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_3conv (Conv1D)   (None, 2066, 512)    786944      ['add_1[0][0]']                  
                                                                                                  
 wo_bias_bpnet_3crop (Cropping1  (None, 2066, 512)   0           ['add_1[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_2 (Add)                    (None, 2066, 512)    0           ['wo_bias_bpnet_3conv[0][0]',    
                                                                  'wo_bias_bpnet_3crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_4conv (Conv1D)   (None, 2034, 512)    786944      ['add_2[0][0]']                  
                                                                                                  
 wo_bias_bpnet_4crop (Cropping1  (None, 2034, 512)   0           ['add_2[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_3 (Add)                    (None, 2034, 512)    0           ['wo_bias_bpnet_4conv[0][0]',    
                                                                  'wo_bias_bpnet_4crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_5conv (Conv1D)   (None, 1970, 512)    786944      ['add_3[0][0]']                  
                                                                                                  
 wo_bias_bpnet_5crop (Cropping1  (None, 1970, 512)   0           ['add_3[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_4 (Add)                    (None, 1970, 512)    0           ['wo_bias_bpnet_5conv[0][0]',    
                                                                  'wo_bias_bpnet_5crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_6conv (Conv1D)   (None, 1842, 512)    786944      ['add_4[0][0]']                  
                                                                                                  
 wo_bias_bpnet_6crop (Cropping1  (None, 1842, 512)   0           ['add_4[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_5 (Add)                    (None, 1842, 512)    0           ['wo_bias_bpnet_6conv[0][0]',    
                                                                  'wo_bias_bpnet_6crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_7conv (Conv1D)   (None, 1586, 512)    786944      ['add_5[0][0]']                  
                                                                                                  
 wo_bias_bpnet_7crop (Cropping1  (None, 1586, 512)   0           ['add_5[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_6 (Add)                    (None, 1586, 512)    0           ['wo_bias_bpnet_7conv[0][0]',    
                                                                  'wo_bias_bpnet_7crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_8conv (Conv1D)   (None, 1074, 512)    786944      ['add_6[0][0]']                  
                                                                                                  
 wo_bias_bpnet_8crop (Cropping1  (None, 1074, 512)   0           ['add_6[0][0]']                  
 D)                                                                                               
                                                                                                  
 add_7 (Add)                    (None, 1074, 512)    0           ['wo_bias_bpnet_8conv[0][0]',    
                                                                  'wo_bias_bpnet_8crop[0][0]']    
                                                                                                  
 wo_bias_bpnet_prof_out_precrop  (None, 1000, 1)     38401       ['add_7[0][0]']                  
  (Conv1D)                                                                                        
                                                                                                  
 wo_bias_bpnet_logitt_before_fl  (None, 1000, 1)     0           ['wo_bias_bpnet_prof_out_precrop[
 atten (Cropping1D)                                              0][0]']                          
                                                                                                  
 gap (GlobalAveragePooling1D)   (None, 512)          0           ['add_7[0][0]']                  
                                                                                                  
 wo_bias_bpnet_logits_profile_p  (None, 1000)        0           ['wo_bias_bpnet_logitt_before_fla
 redictions (Flatten)                                            tten[0][0]']                     
                                                                                                  
 wo_bias_bpnet_logcount_predict  (None, 1)           513         ['gap[0][0]']                    
 ions (Dense)                                                                                     
                                                                                                  
==================================================================================================
Total params: 6,377,986
Trainable params: 6,377,986
Non-trainable params: 0
__________________________________________________________________________________________________
None
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 model_1 (Functional)           [(None, 1000),       6377986     ['input_1[0][0]',                
                                 (None, 1)]                       'input_2[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 1000)         0           ['model_1[0][0]',                
                                                                  'model_1[0][1]']                
                                                                                                  
 lambda_1 (Lambda)              (None, 1000)         0           ['model_1[1][0]',                
                                                                  'model_1[1][1]']                
                                                                                                  
 lambda_2 (Lambda)              (None, 1000)         0           ['lambda[0][0]',                 
                                                                  'lambda_1[0][0]']               
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 1000, 1)      0           ['lambda_2[0][0]']               
                                                                                                  
 conv1d (Conv1D)                (None, 991, 16)      176         ['tf.expand_dims[0][0]']         
                                                                                                  
 flatten (Flatten)              (None, 15856)        0           ['conv1d[0][0]']                 
                                                                                                  
 dense (Dense)                  (None, 48)           761136      ['flatten[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 1)            49          ['dense[0][0]']                  
                                                                                                  
==================================================================================================
Total params: 7,139,347
Trainable params: 7,139,347
Non-trainable params: 0
__________________________________________________________________________________________________
None
(135, 2114, 4) (135, 2114, 4) (135,)
LR: 1e-05
Epoch 1/40
2022-09-27 20:39:51.590469: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201
2022-09-27 20:39:53.754864: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
1/7 [===>..........................] - ETA: 1:09 - loss: 0.1201 - root_mean_squared_error: 0.12012/7 [=======>......................] - ETA: 1s - loss: 0.1450 - root_mean_squared_error: 0.1471  3/7 [===========>..................] - ETA: 1s - loss: 0.1391 - root_mean_squared_error: 0.14084/7 [================>.............] - ETA: 0s - loss: 0.1691 - root_mean_squared_error: 0.17805/7 [====================>.........] - ETA: 0s - loss: 0.1603 - root_mean_squared_error: 0.16876/7 [========================>.....] - ETA: 0s - loss: 0.1532 - root_mean_squared_error: 0.16137/7 [==============================] - ETA: 0s - loss: 0.1518 - root_mean_squared_error: 0.1592
Epoch 1: val_loss improved from inf to 0.15526, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.16.10.dense.48.dense.1.rmse
2022-09-27 20:40:05.783992: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
7/7 [==============================] - 21s 2s/step - loss: 0.1518 - root_mean_squared_error: 0.1592 - val_loss: 0.1553 - val_root_mean_squared_error: 0.1562
Epoch 2/40
1/7 [===>..........................] - ETA: 2s - loss: 0.1268 - root_mean_squared_error: 0.12682/7 [=======>......................] - ETA: 1s - loss: 0.1204 - root_mean_squared_error: 0.12053/7 [===========>..................] - ETA: 1s - loss: 0.1150 - root_mean_squared_error: 0.11544/7 [================>.............] - ETA: 0s - loss: 0.1209 - root_mean_squared_error: 0.12165/7 [====================>.........] - ETA: 0s - loss: 0.1311 - root_mean_squared_error: 0.13326/7 [========================>.....] - ETA: 0s - loss: 0.1352 - root_mean_squared_error: 0.13717/7 [==============================] - ETA: 0s - loss: 0.1408 - root_mean_squared_error: 0.1434
Epoch 2: val_loss improved from 0.15526 to 0.14812, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.16.10.dense.48.dense.1.rmse
7/7 [==============================] - 6s 999ms/step - loss: 0.1408 - root_mean_squared_error: 0.1434 - val_loss: 0.1481 - val_root_mean_squared_error: 0.1487
Epoch 3/40
1/7 [===>..........................] - ETA: 1s - loss: 0.1339 - root_mean_squared_error: 0.13392/7 [=======>......................] - ETA: 1s - loss: 0.1452 - root_mean_squared_error: 0.14573/7 [===========>..................] - ETA: 1s - loss: 0.1320 - root_mean_squared_error: 0.13364/7 [================>.............] - ETA: 0s - loss: 0.1261 - root_mean_squared_error: 0.12785/7 [====================>.........] - ETA: 0s - loss: 0.1351 - root_mean_squared_error: 0.13756/7 [========================>.....] - ETA: 0s - loss: 0.1305 - root_mean_squared_error: 0.13307/7 [==============================] - ETA: 0s - loss: 0.1316 - root_mean_squared_error: 0.1339
Epoch 3: val_loss improved from 0.14812 to 0.14153, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.16.10.dense.48.dense.1.rmse
7/7 [==============================] - 7s 1s/step - loss: 0.1316 - root_mean_squared_error: 0.1339 - val_loss: 0.1415 - val_root_mean_squared_error: 0.1420
Epoch 4/40
1/7 [===>..........................] - ETA: 1s - loss: 0.1120 - root_mean_squared_error: 0.11202/7 [=======>......................] - ETA: 1s - loss: 0.1156 - root_mean_squared_error: 0.11573/7 [===========>..................] - ETA: 1s - loss: 0.1150 - root_mean_squared_error: 0.11504/7 [================>.............] - ETA: 0s - loss: 0.1219 - root_mean_squared_error: 0.12265/7 [====================>.........] - ETA: 0s - loss: 0.1203 - root_mean_squared_error: 0.12096/7 [========================>.....] - ETA: 0s - loss: 0.1220 - root_mean_squared_error: 0.12257/7 [==============================] - ETA: 0s - loss: 0.1236 - root_mean_squared_error: 0.1241
Epoch 4: val_loss improved from 0.14153 to 0.13699, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.16.10.dense.48.dense.1.rmse
7/7 [==============================] - 6s 1s/step - loss: 0.1236 - root_mean_squared_error: 0.1241 - val_loss: 0.1370 - val_root_mean_squared_error: 0.1373
Epoch 5/40
1/7 [===>..........................] - ETA: 2s - loss: 0.1050 - root_mean_squared_error: 0.10502/7 [=======>......................] - ETA: 1s - loss: 0.1206 - root_mean_squared_error: 0.12163/7 [===========>..................] - ETA: 1s - loss: 0.1156 - root_mean_squared_error: 0.11654/7 [================>.............] - ETA: 0s - loss: 0.1157 - root_mean_squared_error: 0.11645/7 [====================>.........] - ETA: 0s - loss: 0.1173 - root_mean_squared_error: 0.11786/7 [========================>.....] - ETA: 0s - loss: 0.1171 - root_mean_squared_error: 0.11767/7 [==============================] - ETA: 0s - loss: 0.1162 - root_mean_squared_error: 0.1167
Epoch 5: val_loss improved from 0.13699 to 0.13357, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.16.10.dense.48.dense.1.rmse
7/7 [==============================] - 6s 1s/step - loss: 0.1162 - root_mean_squared_error: 0.1167 - val_loss: 0.1336 - val_root_mean_squared_error: 0.1339
Epoch 6/40
1/7 [===>..........................] - ETA: 1s - loss: 0.1175 - root_mean_squared_error: 0.11752/7 [=======>......................] - ETA: 1s - loss: 0.1095 - root_mean_squared_error: 0.10983/7 [===========>..................] - ETA: 1s - loss: 0.1119 - root_mean_squared_error: 0.11214/7 [================>.............] - ETA: 0s - loss: 0.1128 - root_mean_squared_error: 0.11305/7 [====================>.........] - ETA: 0s - loss: 0.1138 - root_mean_squared_error: 0.11406/7 [========================>.....] - ETA: 0s - loss: 0.1090 - root_mean_squared_error: 0.10977/7 [==============================] - ETA: 0s - loss: 0.1084 - root_mean_squared_error: 0.1090
Epoch 6: val_loss improved from 0.13357 to 0.13099, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.16.10.dense.48.dense.1.rmse
7/7 [==============================] - 6s 978ms/step - loss: 0.1084 - root_mean_squared_error: 0.1090 - val_loss: 0.1310 - val_root_mean_squared_error: 0.1313
Epoch 7/40
1/7 [===>..........................] - ETA: 2s - loss: 0.1003 - root_mean_squared_error: 0.10032/7 [=======>......................] - ETA: 1s - loss: 0.1141 - root_mean_squared_error: 0.11493/7 [===========>..................] - ETA: 1s - loss: 0.1103 - root_mean_squared_error: 0.11104/7 [================>.............] - ETA: 0s - loss: 0.1079 - root_mean_squared_error: 0.10855/7 [====================>.........] - ETA: 0s - loss: 0.1041 - root_mean_squared_error: 0.10496/7 [========================>.....] - ETA: 0s - loss: 0.1021 - root_mean_squared_error: 0.10287/7 [==============================] - ETA: 0s - loss: 0.1025 - root_mean_squared_error: 0.1031
Epoch 7: val_loss improved from 0.13099 to 0.12882, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.16.10.dense.48.dense.1.rmse
7/7 [==============================] - 7s 1s/step - loss: 0.1025 - root_mean_squared_error: 0.1031 - val_loss: 0.1288 - val_root_mean_squared_error: 0.1291
Epoch 8/40
1/7 [===>..........................] - ETA: 1s - loss: 0.1162 - root_mean_squared_error: 0.11622/7 [=======>......................] - ETA: 1s - loss: 0.1109 - root_mean_squared_error: 0.11103/7 [===========>..................] - ETA: 1s - loss: 0.1025 - root_mean_squared_error: 0.10334/7 [================>.............] - ETA: 0s - loss: 0.1005 - root_mean_squared_error: 0.10125/7 [====================>.........] - ETA: 0s - loss: 0.0996 - root_mean_squared_error: 0.10016/7 [========================>.....] - ETA: 0s - loss: 0.0975 - root_mean_squared_error: 0.09807/7 [==============================] - ETA: 0s - loss: 0.0965 - root_mean_squared_error: 0.0971
Epoch 8: val_loss improved from 0.12882 to 0.12805, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.16.10.dense.48.dense.1.rmse
7/7 [==============================] - 6s 996ms/step - loss: 0.0965 - root_mean_squared_error: 0.0971 - val_loss: 0.1280 - val_root_mean_squared_error: 0.1283
Epoch 9/40
1/7 [===>..........................] - ETA: 1s - loss: 0.1025 - root_mean_squared_error: 0.10252/7 [=======>......................] - ETA: 1s - loss: 0.1000 - root_mean_squared_error: 0.10003/7 [===========>..................] - ETA: 1s - loss: 0.0986 - root_mean_squared_error: 0.09864/7 [================>.............] - ETA: 0s - loss: 0.0907 - root_mean_squared_error: 0.09175/7 [====================>.........] - ETA: 0s - loss: 0.0915 - root_mean_squared_error: 0.09236/7 [========================>.....] - ETA: 0s - loss: 0.0911 - root_mean_squared_error: 0.09187/7 [==============================] - ETA: 0s - loss: 0.0903 - root_mean_squared_error: 0.0910
Epoch 9: val_loss improved from 0.12805 to 0.12776, saving model to MPRA_model_development/models/MPRAModel.Kampman.mSK_K562.t100.p0.5.c300.vconv.16.10.dense.48.dense.1.rmse
7/7 [==============================] - 6s 989ms/step - loss: 0.0903 - root_mean_squared_error: 0.0910 - val_loss: 0.1278 - val_root_mean_squared_error: 0.1281
Epoch 10/40
1/7 [===>..........................] - ETA: 2s - loss: 0.0906 - root_mean_squared_error: 0.09062/7 [=======>......................] - ETA: 1s - loss: 0.0805 - root_mean_squared_error: 0.08113/7 [===========>..................] - ETA: 1s - loss: 0.0872 - root_mean_squared_error: 0.08814/7 [================>.............] - ETA: 0s - loss: 0.0869 - root_mean_squared_error: 0.08765/7 [====================>.........] - ETA: 0s - loss: 0.0840 - root_mean_squared_error: 0.08486/7 [========================>.....] - ETA: 0s - loss: 0.0849 - root_mean_squared_error: 0.08557/7 [==============================] - ETA: 0s - loss: 0.0851 - root_mean_squared_error: 0.0856
Epoch 10: val_loss did not improve from 0.12776
7/7 [==============================] - 2s 315ms/step - loss: 0.0851 - root_mean_squared_error: 0.0856 - val_loss: 0.1286 - val_root_mean_squared_error: 0.1289
Epoch 11/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0957 - root_mean_squared_error: 0.09572/7 [=======>......................] - ETA: 1s - loss: 0.0871 - root_mean_squared_error: 0.08753/7 [===========>..................] - ETA: 1s - loss: 0.0854 - root_mean_squared_error: 0.08574/7 [================>.............] - ETA: 0s - loss: 0.0839 - root_mean_squared_error: 0.08425/7 [====================>.........] - ETA: 0s - loss: 0.0823 - root_mean_squared_error: 0.08266/7 [========================>.....] - ETA: 0s - loss: 0.0817 - root_mean_squared_error: 0.08197/7 [==============================] - ETA: 0s - loss: 0.0799 - root_mean_squared_error: 0.0803
Epoch 11: val_loss did not improve from 0.12776
7/7 [==============================] - 2s 315ms/step - loss: 0.0799 - root_mean_squared_error: 0.0803 - val_loss: 0.1293 - val_root_mean_squared_error: 0.1297
Epoch 12/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0709 - root_mean_squared_error: 0.07092/7 [=======>......................] - ETA: 1s - loss: 0.0746 - root_mean_squared_error: 0.07473/7 [===========>..................] - ETA: 1s - loss: 0.0751 - root_mean_squared_error: 0.07524/7 [================>.............] - ETA: 0s - loss: 0.0768 - root_mean_squared_error: 0.07695/7 [====================>.........] - ETA: 0s - loss: 0.0758 - root_mean_squared_error: 0.07596/7 [========================>.....] - ETA: 0s - loss: 0.0761 - root_mean_squared_error: 0.07627/7 [==============================] - ETA: 0s - loss: 0.0747 - root_mean_squared_error: 0.0749
Epoch 12: val_loss did not improve from 0.12776
7/7 [==============================] - 2s 315ms/step - loss: 0.0747 - root_mean_squared_error: 0.0749 - val_loss: 0.1304 - val_root_mean_squared_error: 0.1308
Epoch 13/40
1/7 [===>..........................] - ETA: 1s - loss: 0.0562 - root_mean_squared_error: 0.05622/7 [=======>......................] - ETA: 1s - loss: 0.0664 - root_mean_squared_error: 0.06713/7 [===========>..................] - ETA: 1s - loss: 0.0700 - root_mean_squared_error: 0.07074/7 [================>.............] - ETA: 0s - loss: 0.0629 - root_mean_squared_error: 0.06465/7 [====================>.........] - ETA: 0s - loss: 0.0669 - root_mean_squared_error: 0.06876/7 [========================>.....] - ETA: 0s - loss: 0.0677 - root_mean_squared_error: 0.06927/7 [==============================] - ETA: 0s - loss: 0.0685 - root_mean_squared_error: 0.0698
Epoch 13: val_loss did not improve from 0.12776
Restoring model weights from the end of the best epoch: 8.
7/7 [==============================] - 2s 323ms/step - loss: 0.0685 - root_mean_squared_error: 0.0698 - val_loss: 0.1313 - val_root_mean_squared_error: 0.1318
Epoch 13: early stopping
TNN loaded from file
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 2114, 4)]    0           []                               
                                                                                                  
 model_1 (Functional)           [(None, 1000),       6377986     ['input_1[0][0]',                
                                 (None, 1)]                       'input_2[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 1000)         0           ['model_1[0][0]',                
                                                                  'model_1[0][1]']                
                                                                                                  
 lambda_1 (Lambda)              (None, 1000)         0           ['model_1[1][0]',                
                                                                  'model_1[1][1]']                
                                                                                                  
 lambda_2 (Lambda)              (None, 1000)         0           ['lambda[0][0]',                 
                                                                  'lambda_1[0][0]']               
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 1000, 1)      0           ['lambda_2[0][0]']               
                                                                                                  
 conv1d (Conv1D)                (None, 991, 16)      176         ['tf.expand_dims[0][0]']         
                                                                                                  
 flatten (Flatten)              (None, 15856)        0           ['conv1d[0][0]']                 
                                                                                                  
 dense (Dense)                  (None, 48)           761136      ['flatten[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 1)            49          ['dense[0][0]']                  
                                                                                                  
==================================================================================================
Total params: 7,139,347
Trainable params: 7,139,347
Non-trainable params: 0
__________________________________________________________________________________________________
None
 1/10 [==>...........................] - ETA: 4s 2/10 [=====>........................] - ETA: 0s 3/10 [========>.....................] - ETA: 0s 4/10 [===========>..................] - ETA: 0s 5/10 [==============>...............] - ETA: 0s 6/10 [=================>............] - ETA: 0s 7/10 [====================>.........] - ETA: 0s 8/10 [=======================>......] - ETA: 0s 9/10 [==========================>...] - ETA: 0s10/10 [==============================] - ETA: 0s10/10 [==============================] - 2s 196ms/step
[-0.0060014343, -0.045235287, 0.002069917, -0.034386903, -0.1126763, -0.039074894, -0.03763935, -0.004455541, -0.03723705, -0.034450043, -0.016783252, -0.042381927, -0.037063166, -0.08101198, -0.0077677313, -0.012719225, -0.045529045, -0.005102276, 0.062981874, -0.008461846, 0.0061758994, -0.030781256, 0.077382244, 0.020142144, 0.019200034, -0.04592699, 0.04718858, 0.07803778, -0.082596846, 0.02352871, -0.016569404, -0.01181349, -0.015356084, -0.0035925505, 0.014798771, 0.01260384, -0.00882101, -0.020936716, -0.03379593, -0.029009333, -0.030601725, 0.0023592864, 0.03841927, -0.05062589, 0.0010730732, -0.023208972, 0.0038700572, -0.044276264, -0.057322323, -0.03334194, 0.03980883, 0.028037235, 0.03576792, -0.105385005, 0.0111153815, 0.0059294566, 0.031264536, 0.064234965, 0.065215126, -0.030470297, -0.072533846, -0.017993947, -0.015645051, 0.0032439167, -0.00020419122, 0.060636505, -0.05773218, -0.03673639, -0.07551611, 0.13947487, 0.07171424, 0.09222889, -0.4047005, -0.0038922043, -0.04326834, -0.115861535, -0.0128732165, -0.008055882, 0.07284212, 0.035238832, -0.038725916, 0.021840898, 0.012412283, 0.04523543, 0.012272683, -0.093355075, -0.021522079, 0.03088952, -0.028198233, 0.05167309, -0.041418042, -0.0552158, 0.12849426, -0.016791731, -0.06692526, 0.004770865, -0.10456756, 0.042393137, -0.028254518, 0.0028683178, 0.017673263, -0.083646685, -0.011214814, -0.030286979, -0.0027680688, -0.13140874, -0.024909604, -0.02050584, -0.033841632, -0.13319057, -0.007313525, -0.07908926, 0.007596935, 0.007665077, -0.076513596, -0.13717307, -0.09305385, 0.023889154, -0.07154821, 0.023353575, -0.08457678, -0.009263854, 0.0024230892, -0.028383313, 0.03146295, 0.14974976, 0.09821827, -0.12411367, 0.17374022, -0.010918566, 0.090769485, 0.1597659, -0.038347676, -0.037056047, -0.031936016, 0.02173938, 0.13068278, -0.036119293, -0.032656327, -0.041706987, 0.22593342, 0.0006911445, -0.023316985, -0.16129583, 0.104849614, -0.069070846, -0.22601861, 0.19812195, -0.27648804, -0.22413222, -0.40599298]
[-0.0905034  -0.09947216  0.07853377  0.07739935 -0.26832333 -0.06778263
 -0.08546479  0.08648197  0.07961277  0.07720217 -0.08014117 -0.08105874
 -0.09328441 -0.09695353 -0.11880182 -0.06326722 -0.08434247 -0.09411035
  0.0921365   0.09063613  0.12313518 -0.07950069  0.09031201  0.0710011
 -0.10043573  0.11124648  0.10079366  0.09531208 -0.06277929 -0.11083511
 -0.10710893 -0.11494793  0.13846627  0.11033365  0.09340035  0.09148435
  0.0829305  -0.06689062 -0.07912685 -0.08899292 -0.09257795  0.0991051
  0.08540135 -0.10334674  0.11694617  0.10851879  0.08058769 -0.12419123
 -0.12557973 -0.06900014  0.15094079  0.14292263  0.11062875 -0.16626157
  0.12909251  0.07481506  0.10535965  0.09083616  0.10223201 -0.07872573
 -0.08115115 -0.10202431  0.1065836   0.10569526  0.09134408 -0.10430546
 -0.11229523  0.08098407 -0.07248487  0.10833224  0.11191964  0.09127144
 -0.34156207  0.16014625 -0.10213176 -0.1030441   0.18302456  0.08710979
  0.16541972  0.15007845 -0.11375303 -0.13332473  0.15195966  0.10983172
 -0.12349412 -0.11492698 -0.15814887  0.08052575 -0.11003885  0.08794768
 -0.10758457 -0.14492674  0.11402104 -0.10341273 -0.11568559  0.11976604
 -0.09906955  0.11174096 -0.11254208 -0.1282223   0.0830264  -0.1545139
 -0.1043491  -0.14034679  0.11594063 -0.13771265 -0.16025063 -0.14683859
  0.1183183  -0.1315937  -0.13619249 -0.12484662  0.15976923  0.10062947
 -0.11664557 -0.1552405  -0.17203074  0.1055946  -0.10456964  0.14444356
 -0.11645929 -0.17384205  0.10422415 -0.12774052  0.12609592  0.12372607
  0.23101375 -0.2028399  -0.22582155  0.17918628  0.12624905  0.20775655
 -0.1733779  -0.18529817 -0.1419532   0.16041179  0.15815749 -0.18451102
 -0.19436191 -0.19201529  0.18251119 -0.17792116 -0.17916801 -0.23552507
  0.18936244 -0.22218015 -0.3508249   0.29389578 -0.33032155 -0.29608878
 -0.52658078]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 151 entries, 0 to 150
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   TNN     151 non-null    float32
 1   Y       151 non-null    float64
dtypes: float32(1), float64(1)
memory usage: 1.9 KB
None
         TNN         Y
0  -0.006001 -0.090503
1  -0.045235 -0.099472
2   0.002070  0.078534
3  -0.034387  0.077399
4  -0.112676 -0.268323
5  -0.039075 -0.067783
6  -0.037639 -0.085465
7  -0.004456  0.086482
8  -0.037237  0.079613
9  -0.034450  0.077202
10 -0.016783 -0.080141
11 -0.042382 -0.081059
12 -0.037063 -0.093284
13 -0.081012 -0.096954
14 -0.007768 -0.118802
15 -0.012719 -0.063267
16 -0.045529 -0.084342
17 -0.005102 -0.094110
18  0.062982  0.092136
19 -0.008462  0.090636
1/9 [==>...........................] - ETA: 0s2/9 [=====>........................] - ETA: 0s3/9 [=========>....................] - ETA: 0s4/9 [============>.................] - ETA: 0s5/9 [===============>..............] - ETA: 0s6/9 [===================>..........] - ETA: 0s7/9 [======================>.......] - ETA: 0s8/9 [=========================>....] - ETA: 0s9/9 [==============================] - ETA: 0s9/9 [==============================] - 1s 88ms/step
[-0.045529045, 0.0061758994, -0.03334194, -0.03673639, 0.22593342, -0.024909604, -0.021522079, -0.03379593, -0.13140874, -0.029009333, -0.028254518, -0.16129583, -0.02050584, 0.028037235, -0.06692526, -0.07908926, 0.03576792, -0.10456756, -0.00020419122, -0.034386903, 0.065215126, 0.017673263, -0.08457678, -0.037063166, 0.01260384, -0.038725916, 0.077382244, -0.057322323, -0.0035925505, 0.09821827, -0.13319057, -0.034450043, 0.062981874, -0.4047005, 0.13068278, -0.005102276, -0.042381927, 0.10484953, 0.007665077, -0.009263854, -0.1126763, 0.042393137, -0.0060014343, -0.072533846, -0.008055882, 0.03088952, 0.031264536, 0.0006911445, -0.030601725, -0.082596846, -0.04592699, -0.008461846, -0.012719225, -0.030781256, 0.03146295, 0.14974976, -0.05062589, 0.0038700572, 0.03980883, -0.039074894, -0.13717307, -0.0552158, 0.023889154, -0.40599334, -0.04326834, 0.1597659, 0.0010730732, 0.064234965, 0.02173938, 0.03841927, -0.12411367, -0.038347676, 0.13947487, -0.007313525, -0.041418042, 0.04523543, -0.105385005, -0.033841632, 0.07803778, 0.04718858, 0.002069917, -0.023208972, 0.014798771, 0.023353575, 0.09222889, -0.07551611, 0.0023592864, 0.0032439167, -0.05773218, -0.044276264, 0.07284212, -0.017993947, -0.22413248, -0.06907068, -0.016569404, -0.0077677313, -0.27648798, 0.0028683178, -0.023316985, 0.05167309, 0.12849426, -0.028198233, 0.007596935, 0.090769485, -0.076513596, -0.045235287, -0.030470297, -0.031936016, -0.115861535, -0.015356084, -0.09305385, 0.02352871, 0.0111153815, 0.17374022, 0.020142144, -0.030286979, 0.012272683, -0.08101198, 0.07171424, -0.03763935, -0.00882101, 0.19812095, 0.035238832, -0.020936716, -0.016783252, -0.015645051, -0.011214814, 0.021840898, 0.060636494, -0.07154841, 0.0059297844, -0.0027679864, -0.016791398, -0.03705607, -0.041707]
[-0.08434247  0.12313518 -0.06900014  0.08098407  0.18251119 -0.16025063
 -0.15814887 -0.07912685 -0.13771265 -0.08899292 -0.11254208 -0.23552507
 -0.14683859  0.14292263 -0.11568559 -0.12484662  0.11062875 -0.09906955
  0.09134408  0.07739935  0.10223201  0.0830264  -0.11645929 -0.09328441
  0.09148435 -0.11375303  0.09031201 -0.12557973  0.11033365  0.23101375
 -0.1315937   0.07720217  0.0921365  -0.34156207  0.15815749 -0.09411035
 -0.08105874  0.18936244  0.10062947 -0.17384205 -0.26832333  0.11174096
 -0.0905034  -0.08115115  0.08710979  0.08052575  0.10535965 -0.17792116
 -0.09257795 -0.06277929  0.11124648  0.09063613 -0.06326722 -0.07950069
  0.12609592  0.12372607 -0.10334674  0.08058769  0.15094079 -0.06778263
 -0.1552405  -0.14492674  0.1055946  -0.52658078 -0.10213176  0.20775655
  0.11694617  0.09083616  0.16041179  0.08540135 -0.2028399  -0.1733779
  0.10833224 -0.13619249 -0.10758457  0.10983172 -0.16626157  0.1183183
  0.09531208  0.10079366  0.07853377  0.10851879  0.09340035  0.14444356
  0.09127144 -0.07248487  0.0991051   0.10569526 -0.11229523 -0.12419123
  0.16541972 -0.10202431 -0.29608878 -0.22218015 -0.10710893 -0.11880182
 -0.33032155 -0.1282223  -0.17916801  0.08794768  0.11402104 -0.11003885
  0.15976923  0.12624905 -0.11664557 -0.09947216 -0.07872573 -0.1419532
 -0.1030441   0.13846627 -0.17203074 -0.11083511  0.12909251 -0.22582155
  0.0710011  -0.14034679 -0.12349412 -0.09695353  0.11191964 -0.08546479
  0.0829305   0.29389578  0.15007845 -0.06689062 -0.08014117  0.1065836
 -0.1043491  -0.13332473 -0.10430546 -0.10456964  0.07481506  0.11594063
 -0.10341273 -0.18529817 -0.19201529]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 135 entries, 0 to 134
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   TNN     135 non-null    float32
 1   Y       135 non-null    float64
dtypes: float32(1), float64(1)
memory usage: 1.7 KB
None
         TNN         Y
0  -0.045529 -0.084342
1   0.006176  0.123135
2  -0.033342 -0.069000
3  -0.036736  0.080984
4   0.225933  0.182511
5  -0.024910 -0.160251
6  -0.021522 -0.158149
7  -0.033796 -0.079127
8  -0.131409 -0.137713
9  -0.029009 -0.088993
10 -0.028255 -0.112542
11 -0.161296 -0.235525
12 -0.020506 -0.146839
13  0.028037  0.142923
14 -0.066925 -0.115686
15 -0.079089 -0.124847
16  0.035768  0.110629
17 -0.104568 -0.099070
18 -0.000204  0.091344
19 -0.034387  0.077399
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 379ms/step
[-0.004455541, -0.0128732165, -0.036119293, -0.2260188, -0.010918566, -0.01181349, 0.004770865, 0.012412283, -0.0038922043, 0.019200034, -0.093355075, -0.032656327, -0.03723705, -0.028383313, 0.0024230892, -0.083646685]
[ 0.08648197  0.18302456 -0.18451102 -0.3508249   0.17918628 -0.11494793
  0.11976604  0.15195966  0.16014625 -0.10043573 -0.11492698 -0.19436191
  0.07961277 -0.12774052  0.10422415 -0.1545139 ]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 16 entries, 0 to 15
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   TNN     16 non-null     float32
 1   Y       16 non-null     float64
dtypes: float32(1), float64(1)
memory usage: 320.0 bytes
None
         TNN         Y
0  -0.004456  0.086482
1  -0.012873  0.183025
2  -0.036119 -0.184511
3  -0.226019 -0.350825
4  -0.010919  0.179186
5  -0.011813 -0.114948
6   0.004771  0.119766
7   0.012412  0.151960
8  -0.003892  0.160146
9   0.019200 -0.100436
10 -0.093355 -0.114927
11 -0.032656 -0.194362
12 -0.037237  0.079613
13 -0.028383 -0.127741
14  0.002423  0.104224
15 -0.083647 -0.154514
spearman TNN-all: 0.6861171139769955
pearson TNN-all: 0.7229093592888353
spearman TNN-train: 0.6961906155497025
pearson TNN-train: 0.737907783932835
spearman TNN-test: 0.6264705882352941
pearson TNN-test: 0.6907404785735192
